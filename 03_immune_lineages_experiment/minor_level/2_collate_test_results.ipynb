{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7cc55-3b46-46c2-bdd6-6e34ffdc37f1",
   "metadata": {},
   "source": [
    "# Collate model predictions from purity-level partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a63a1-8e52-493c-b685-5a419fa97191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as adata\n",
    "import scanpy as sc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly as plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cef7f-433e-4db0-8f5f-942d374522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/03_immune_lineages_experiment/minor_level\"\n",
    "purity_levels = [0.5]\n",
    "c_types = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"T cells CD4+\",\n",
    "    \"T cells CD8+\",\n",
    "    \"Endothelial\",\n",
    "    \"CAFs\",\n",
    "    \"Macrophage\",\n",
    "    \"PVL\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"Plasmablasts\",\n",
    "    \"B cells Memory\",\n",
    "    \"Monocyte\",\n",
    "    \"Cycling_Myeloid\",\n",
    "    \"Cycling T-cells\",\n",
    "    \"NK cells\",\n",
    "    \"NKT cells\",\n",
    "    \"DCs\",\n",
    "    \"B cells Naive\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fe163",
   "metadata": {},
   "source": [
    "## Prepare our groundtruth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeca089",
   "metadata": {},
   "source": [
    "If we haven't extracted groundtruth from test AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "truth_df = test_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "truth_df = truth_df[c_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da914fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results/ directory if it hasn't existed yet\n",
    "Path(prefix).joinpath(\"data/results/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5431507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into csv beautifully\n",
    "truth_df.to_csv(Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b952ea",
   "metadata": {},
   "source": [
    "If we have already extracted the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562086a-5077-43a2-989e-422ee88109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load truth.csv\n",
    "truth_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "truth_df = truth_df[c_types]\n",
    "truth_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcc9c0-de70-498e-9bf9-d677e877a119",
   "metadata": {},
   "source": [
    "### CIBERSORTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we run in normal mode, the results file is called CIBERSORTx_Results\n",
    "# If we run in Smode or Bmode, the results file will be called CIBERSORTx_Adjusted.txt\n",
    "# Adjust the filename accordingy\n",
    "results_f = \"CIBERSORTx_Results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ec1b6-6624-4277-9bb5-7f50f2d348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cbx/results/{pur_lvl}/{results_f}\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_preds_df.drop([\"P-value\", \"Correlation\", \"RMSE\"], axis=1, inplace=True)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/cbx.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4b1f2-ef03-4f8f-a5de-3da2884fc6cd",
   "metadata": {},
   "source": [
    "### Scaden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223be65-2e97-4cb4-92ea-bf5621cc7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/scaden/{pur_lvl}/results_{pur_lvl}.txt\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/scaden.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb013ab5-c4d4-4556-baaf-93229c915b70",
   "metadata": {},
   "source": [
    "### EPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1253f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(\n",
    "            f\"data/epic/cbx_sig_matrix/results/{pur_lvl}/results.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Replace otherCells in predictions by Cancer Epithelial\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"otherCells\": \"Cancer Epithelial\",\n",
    "            \"B.cells.Memory\": \"B cells Memory\",\n",
    "            \"B.cells.Naive\": \"B cells Naive\",\n",
    "            \"T.cells.CD8.\": \"T cells CD8+\",\n",
    "            \"T.cells.CD4.\": \"T cells CD4+\",\n",
    "            \"NK.cells\": \"NK cells\",\n",
    "            \"NKT.cells\": \"NKT cells\",\n",
    "            \"Normal.Epithelial\": \"Normal Epithelial\",\n",
    "            \"Cycling.T.cells\": \"Cycling T-cells\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/epic.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5b216",
   "metadata": {},
   "source": [
    "### CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which experiments we'd like to generate results for\n",
    "experiment = \"expr_1_original_cellstate_1330_per_ctype\"\n",
    "\n",
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cpm/{experiment}/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/epic.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9ce78",
   "metadata": {},
   "source": [
    "### bisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14da92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bisque/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Get correct groundtruth subset\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57285182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bisque.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60dd49",
   "metadata": {},
   "source": [
    "### DWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/dwls/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "            \"B_cells_Memory\": \"B cells Memory\",\n",
    "            \"B_cells_Naive\": \"B cells Naive\",\n",
    "            \"T_cells_CD4\": \"T cells CD4+\",\n",
    "            \"T_cells_CD8\": \"T cells CD8+\",\n",
    "            \"NK_cells\": \"NK cells\",\n",
    "            \"NKT_cells\": \"NKT cells\",\n",
    "            \"Cycling_T_cells\": \"Cycling T-cells\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/dwls.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c86510",
   "metadata": {},
   "source": [
    "## MuSiC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/music/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1df796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/music.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09447fa",
   "metadata": {},
   "source": [
    "## hspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "\n",
    "    # Iterate over each of the 20 partitions\n",
    "    for partition in list(range(0, 20, 1)):\n",
    "\n",
    "        # Read and reorganize  index and columns to match truth_df\n",
    "        subset_preds_df = pd.read_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/results/{pur_lvl}/{partition}/results.csv\"\n",
    "            ),\n",
    "            sep=\",\",\n",
    "            index_col=0,\n",
    "        )\n",
    "\n",
    "        # Fix up column names\n",
    "        subset_preds_df.rename(\n",
    "            columns={\n",
    "                \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "                \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "                \"B_cells_Memory\": \"B cells Memory\",\n",
    "                \"B_cells_Naive\": \"B cells Naive\",\n",
    "                \"T_cells_CD4\": \"T cells CD4+\",\n",
    "                \"T_cells_CD8\": \"T cells CD8+\",\n",
    "                \"NK_cells\": \"NK cells\",\n",
    "                \"NKT_cells\": \"NKT cells\",\n",
    "                \"Cycling_T_cells\": \"Cycling T-cells\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        preds_l.append(subset_preds_df)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/hspe.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132380b",
   "metadata": {},
   "source": [
    "## BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bprism/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "            \"B_cells_Memory\": \"B cells Memory\",\n",
    "            \"B_cells_Naive\": \"B cells Naive\",\n",
    "            \"T_cells_CD4\": \"T cells CD4+\",\n",
    "            \"T_cells_CD8\": \"T cells CD8+\",\n",
    "            \"NK_cells\": \"NK cells\",\n",
    "            \"NKT_cells\": \"NKT cells\",\n",
    "            \"Cycling_T_cells\": \"Cycling T-cells\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec83f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bprism.csv\"), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
