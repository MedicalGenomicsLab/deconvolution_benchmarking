{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b36abf93-9948-47fb-bad3-93aba6d06df9",
   "metadata": {},
   "source": [
    "# Prepare training and test data for specific tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd736f3-3757-4f80-a2a8-bfede8929326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as adata\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import ChainMap\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a483-c2d7-42fa-af67-8452637f6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/05_external_scrna_validation/bassez_et_al\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9580-601c-4e92-bc24-6ddecf542c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training patient IDs\n",
    "train_p_ids = [\n",
    "    # HER2+\n",
    "    \"BIOKEY_13\",\n",
    "    # ER+\n",
    "    \"BIOKEY_3\",\n",
    "    \"BIOKEY_5\",\n",
    "    \"BIOKEY_12\",\n",
    "    \"BIOKEY_18\",\n",
    "    \"BIOKEY_22\",\n",
    "    \"BIOKEY_24\",\n",
    "    \"BIOKEY_27\",\n",
    "    \"BIOKEY_29\",\n",
    "    \"BIOKEY_30\",\n",
    "    \"BIOKEY_40\",\n",
    "    \"BIOKEY_42\",\n",
    "    # TNBC\n",
    "    \"BIOKEY_2\",\n",
    "    \"BIOKEY_9\",\n",
    "    \"BIOKEY_10\",\n",
    "    \"BIOKEY_11\",\n",
    "    \"BIOKEY_14\",\n",
    "    \"BIOKEY_15\",\n",
    "    \"BIOKEY_33\",\n",
    "    \"BIOKEY_35\",\n",
    "    \"BIOKEY_36\",\n",
    "    \"BIOKEY_41\",\n",
    "]\n",
    "# Test patient IDs\n",
    "test_p_ids = [\n",
    "    # HER2+\n",
    "    \"BIOKEY_28\",\n",
    "    # ER+\n",
    "    \"BIOKEY_4\",\n",
    "    \"BIOKEY_6\",\n",
    "    \"BIOKEY_7\",\n",
    "    \"BIOKEY_17\",\n",
    "    \"BIOKEY_21\",\n",
    "    \"BIOKEY_37\",\n",
    "    # TNBC\n",
    "    \"BIOKEY_1\",\n",
    "    \"BIOKEY_16\",\n",
    "    \"BIOKEY_19\",\n",
    "    \"BIOKEY_26\",\n",
    "    \"BIOKEY_31\",\n",
    "]\n",
    "pur_lvls = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "c_types = [\n",
    "    \"Cancer_cell\",\n",
    "    \"T_cell\",\n",
    "    \"B_cell\",\n",
    "    \"Myeloid_cell\",\n",
    "    \"Endothelial_cell\",\n",
    "    \"Fibroblast\",\n",
    "    \"Mast_cell\",\n",
    "    \"pDC\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b050fc63",
   "metadata": {},
   "source": [
    "## 0. Process simulated test mixtures\n",
    "- Grab the .h5ad file containing all test mixture we previously generated \n",
    "- Also save it into partitions corresponding to purity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up test mixture AnnData object\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs.copy()\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data into 19 patitions corresponding to 19 purity levels\n",
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer_cell\"] == pur_lvl]\n",
    "    subset_test_counts_df = test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    subset_test_counts_df.T.to_csv(\n",
    "        Path(prefix).joinpath(f\"data/test/test_counts_{pur_lvl}_pur_lvl.tsv\"), sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c916e7a4",
   "metadata": {},
   "source": [
    "## 2. Prepare data for each method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e890717f",
   "metadata": {},
   "source": [
    "#### Load single-cell metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38af95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all metadata\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Miniatlas_meta_9_10.tsv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Split into train and test\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]\n",
    "test_meta_df = meta_df[meta_df[\"Patient\"].isin(test_p_ids)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "103a6ece",
   "metadata": {},
   "source": [
    "#### Load single-cell reference containing only original cells processed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db61a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AnnData object (rows are cells, columns are genes)\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "\n",
    "# Most methods require single-cell reference with cells as columns and genes as columns\n",
    "# Transpose the anndata\n",
    "train_sc_df = train_sc_adata.to_df().T\n",
    "\n",
    "# Rename index and column names\n",
    "train_sc_df.index.name = \"gene_symbol\"\n",
    "train_sc_df.columns.name = \"cell_id\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a11ece1a-ed29-4bcb-88d0-eeb7c81b1c22",
   "metadata": {},
   "source": [
    "#### 1. CIBERSORTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy single-cell reference\n",
    "cbx_sc_df = train_sc_df.copy()\n",
    "\n",
    "# Rename index\n",
    "cbx_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ddcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBX requires a single-cell reference matrix with cell labels as columns and gene symbols as rows\n",
    "# First make very sure that cell ids in train_sc_df and train_sc_adata.var are in the same order\n",
    "assert np.array_equal(\n",
    "    cbx_sc_df.columns.values, train_sc_adata.obs[\"cell_labels\"].index.values\n",
    ")\n",
    "\n",
    "# Then simply replace columns with cell labels\n",
    "cbx_sc_df.columns = train_sc_adata.obs[\"cell_labels\"].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c72822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output beautifully\n",
    "cbx_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/cbx/scRNA_ref.tsv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f8c67e1-2627-48e0-afd9-313e7da7cc02",
   "metadata": {},
   "source": [
    "#### 2. Scaden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "970a4f2f-21f8-42f4-9367-c704ca3f2792",
   "metadata": {},
   "source": [
    "#### Prepare AnnData training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the concatenate AnnData object that contains all train simulated mixtures\n",
    "scaden_train_adata = sc.read_h5ad(\n",
    "    Path(prefix).joinpath(\"data/train/training_sim_mixts.h5ad\")\n",
    ")\n",
    "scaden_train_counts_df = scaden_train_adata.to_df()\n",
    "scaden_train_labels_df = scaden_train_adata.obs\n",
    "\n",
    "# Remove \"batch\" column in obs and replace NaN by 0\n",
    "scaden_train_adata.obs = scaden_train_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "\n",
    "# Scaden requires cell fractions DataFrame to have a column call \"ds\"\n",
    "# This column is supposed to store info on what dataset each row comes from\n",
    "# And the during training we can delect which dataset gets used for training, which is quite handy\n",
    "# However, in this case, there is only 1 dataset\n",
    "# Make all row ds=\"Bassez_et_al\"\n",
    "scaden_train_adata.obs[\"ds\"] = \"Bassez_et_al\"\n",
    "\n",
    "# add cell types and signature genes\n",
    "scaden_train_adata.uns[\"cell_types\"] = c_types\n",
    "scaden_train_adata.uns[\"unknown\"] = \"\"\n",
    "\n",
    "# Rename index and columns properly\n",
    "scaden_train_adata.obs.index.name = \"mixture_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data beautifully\n",
    "scaden_train_adata.write_h5ad(Path(prefix).joinpath(\"data/scaden/train_counts.h5ad\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adbd1a1e",
   "metadata": {},
   "source": [
    "### 3. CPM\n",
    "Cannot be run as it requires UMAP coordinates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7743db9",
   "metadata": {},
   "source": [
    "### 4. bisque\n",
    "bisque expect a .h5ad file holding non-logs single-cell gene counts in the bique/ folder <br>\n",
    "This file would have been previously generated for CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95864d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train metadata\n",
    "bisque_meta_df = train_meta_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patieint id, cell labels and cell ids into a phenotype DataFrame\n",
    "pheno_df = bisque_meta_df[[\"Patient\", \"cell_labels\"]].reset_index()\n",
    "pheno_df.columns = [\"cell_ids\", \"patient_ids\", \"cell_labels\"]\n",
    "\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/bisque/phenotypes.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone single-cell reference\n",
    "bisque_sc_df = train_sc_df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df3d16d",
   "metadata": {},
   "source": [
    "#### If we're using scaled non-logged counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "bisque_sc_df = bisque_sc_df[pheno_df[\"cell_ids\"].values]\n",
    "\n",
    "# Normalize data\n",
    "mms = pp.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaled_sc_arr = mms.fit_transform(bisque_sc_df.T).T\n",
    "bisque_scaled_sc_df = pd.DataFrame(\n",
    "    scaled_sc_arr, index=bisque_sc_df.index, columns=bisque_sc_df.columns\n",
    ")\n",
    "\n",
    "# Save scaled linear counts\n",
    "bisque_scaled_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bisque/scaled_scRNA_ref.tsv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dacbd32",
   "metadata": {},
   "source": [
    "### 5. DWLS\n",
    "DWLS only expects single cell labels accompanying the single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone single-cell reference and metadata\n",
    "dwls_sc_df = train_sc_df.copy()\n",
    "dwls_meta_df = train_meta_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = dwls_meta_df[[\"cell_labels\"]].sort_index()\n",
    "labels_df.to_csv(Path(prefix).joinpath(\"data/dwls/single_cell_labels.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "dwls_sc_df = dwls_sc_df[labels_df.index]\n",
    "\n",
    "dwls_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/dwls/scRNA_ref.tsv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8ab4ca7",
   "metadata": {},
   "source": [
    "### 6. EPIC\n",
    "EPIC relies on the signature matrix and marker genes generated by CIBERSORTx to run <br>\n",
    "This processing script assumes that these 2 files have already been put in the data/epic folders\n",
    "- Signature matrix (containing all genes): cbx_sig_matrix.txt\n",
    "- Marker genes (a subset of signature matrix): cbx_sig_matrix.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All CBX signature matrices are the same across tumour purity levels\n",
    "# Grab one\n",
    "cbx_sig_matrix_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/CIBERSORTx_sigmatrix.txt\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# EPIC assumes the \"unknown\" cells in a tumour is cancer cells\n",
    "# Therefore we need to drop Cancer Epithelial from the signature matrix\n",
    "cbx_sig_matrix_df.drop([\"Cancer_cell\"], axis=1, inplace=True)\n",
    "\n",
    "# Save signature matrix beautifully\n",
    "cbx_sig_matrix_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/reference_profiles.tsv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Extract marker genes from marker gene profiles and save into a .csv\n",
    "marker_gene_labels_df = cbx_sig_matrix_df.index.to_frame()\n",
    "marker_gene_labels_df.rename(columns={\"NAME\": \"gene_symbol\"}, inplace=True)\n",
    "\n",
    "marker_gene_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/marker_gene_symbols.tsv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b521257f",
   "metadata": {},
   "source": [
    "### 7. hspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8323c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone single-cell reference and metadata\n",
    "hspe_sc_df = train_sc_df.copy()\n",
    "hspe_meta_df = train_meta_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44952f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log1p (i.e. add 1 and apply log2)\n",
    "# Both dtangle and hspe only mention log2 without + 1. This will lead to undefined output, as log2(0) = infinity. We therefore added 1 to gene expressions to avoid this\n",
    "# 0 gene expression values will stil return 0 after log1p transformation\n",
    "hspe_log_sc_df = np.log2(hspe_sc_df + 1)\n",
    "\n",
    "# Also oth dtangle and hspe require bulk mixtures and single-cell reference to have genes as columns and rows as samples. We need to tranpose it\n",
    "hspe_log_sc_df = hspe_log_sc_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test count DataFrames and transpose them so genes are columns and samples are rows\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_mixtures.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)\n",
    "\n",
    "# Apply log1p one test counts\n",
    "log_test_counts_df = np.log2(test_counts_df + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc44b5e",
   "metadata": {},
   "source": [
    "##### Save train & test counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56504c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving train and test counts , do a sanity check to make sure train and test DataFrames have the same genes in the same order\n",
    "assert np.array_equal(\n",
    "    hspe_log_sc_df.columns.to_numpy(), log_test_counts_df.columns.to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9da2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell data\n",
    "hspe_log_sc_df.to_csv(Path(prefix).joinpath(\"data/hspe/scRNA_ref.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data by purity levels\n",
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer_cell\"] == pur_lvl]\n",
    "    subset_test_counts_df = log_test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    # Within each tumour purity, split data into 10 shards\n",
    "    # This allows us to paralellize the run into 190-fold\n",
    "    for shard in tqdm(list(range(0, 20, 1))):\n",
    "        shard_obs_df = np.array_split(subset_obs_df, 20)[shard]\n",
    "        shard_test_counts_df = subset_test_counts_df.loc[shard_obs_df.index, :]\n",
    "\n",
    "        shard_test_counts_df.to_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/logged_test_counts_{pur_lvl}_pur_lvl_{shard}.tsv\"\n",
    "            ),\n",
    "            sep=\"\\t\",\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ec3ca82",
   "metadata": {},
   "source": [
    "##### Extract pure samples\n",
    "Both dtangle and hspe require a pure_samples variable. This is a list variable, in which each item corresponds to one cell type and indexes of all cells of the same type in the single-cell reference DataFrame <br>\n",
    "\n",
    "We need to retrieve cell type of the single-cell reference data and save this information into a .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94282971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone metadata\n",
    "hspe_meta_df = train_meta_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of log_train_sc_df() so we have order of cell ids as the indexes\n",
    "reset_hspe_log_sc_df = hspe_log_sc_df.reset_index()\n",
    "\n",
    "# Iterate over cell types and extract cell indexes from single-cell reference\n",
    "pure_samples_d = {}\n",
    "\n",
    "for c_type in tqdm(hspe_meta_df[\"cell_labels\"].unique()):\n",
    "    c_ids = (hspe_meta_df[hspe_meta_df[\"cell_labels\"] == c_type]).index.tolist()\n",
    "    c_indexes = reset_hspe_log_sc_df[reset_hspe_log_sc_df[\"cell_id\"].isin(c_ids)].index\n",
    "\n",
    "    # Python starts indexes from 0 and R starts from 1\n",
    "    # Add 1 to index and add to pure_samples_d\n",
    "    pure_samples_d[c_type] = (c_indexes + 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pure_samples_d into a json file\n",
    "json.dump(\n",
    "    pure_samples_d,\n",
    "    open(Path(prefix).joinpath(f\"data/hspe/pure_samples.json\"), \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "337f5d7d",
   "metadata": {},
   "source": [
    "### 8. MuSiC\n",
    "MuSiC requires single-cell and bulk expressions in ExpressionSet objects <br>\n",
    "The single-cell ExpressionSet also needs to a phenoType item containing\n",
    "- **sampleID**        index of patient\n",
    "- **SubjectName**      patient id\n",
    "- **cellTypeID**       index of cell type\n",
    "- **cellType**         cell annotation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone single-cell reference and metadata\n",
    "music_sc_df = train_sc_df.copy()\n",
    "music_meta_df = train_meta_df.copy()\n",
    "\n",
    "# Rearrange indexes in meta DF to match order of counts DataFrame\n",
    "music_meta_df = music_meta_df.reindex(music_sc_df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86ccc7e5",
   "metadata": {},
   "source": [
    "Metadata for running MuSiC with neither marker genes nor cell subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"Patient\" + \"celltype_major columns\" and rename columns to match MuSiC requirements\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].rename(\n",
    "    columns={\"Patient\": \"SubjectName\", \"cell_labels\": \"cellType\"}\n",
    ")\n",
    "\n",
    "pheno_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69176b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode cell labels into number to use as cellTypeID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(c_types)\n",
    "pheno_df[\"cellTypeID\"] = l_encoder.transform(pheno_df[\"cellType\"]) + 1\n",
    "\n",
    "# Encode patient ids into number to use as sampleID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(pheno_df[\"SubjectName\"].unique())\n",
    "pheno_df[\"sampleID\"] = l_encoder.transform(pheno_df[\"SubjectName\"]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pheno DataFrame\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/music/pheno.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train counts\n",
    "music_sc_df = music_sc_df[pheno_df.index]\n",
    "music_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/music/scRNA_ref.tsv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "096beb28",
   "metadata": {},
   "source": [
    "### 9. BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone single-cell reference and metadata\n",
    "bprism_sc_df = train_sc_df.copy()\n",
    "bprism_meta_df = train_meta_df.copy()\n",
    "\n",
    "# Rearrange indexes in meta DF to match order of counts DataFrame\n",
    "bprism_meta_df = bprism_meta_df.reindex(bprism_sc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9edcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels\n",
    "bprism_meta_df.rename(columns={\"cell_labels\": \"cell_type_labels\"}, inplace=True)\n",
    "bprism_meta_df[[\"cell_type_labels\"]].to_csv(\n",
    "    Path(prefix).joinpath(\"data/bprism/single_cell_labels.tsv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74be9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell counts\n",
    "bprism_sc_df.T.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bprism/scRNA_ref.tsv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
