{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b36abf93-9948-47fb-bad3-93aba6d06df9",
   "metadata": {},
   "source": [
    "# Prepare training and test data for specific tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd736f3-3757-4f80-a2a8-bfede8929326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as adata\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a483-c2d7-42fa-af67-8452637f6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "prefix = \"???/deconvolution_benchmarking/04_tcga_bulk_validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9580-601c-4e92-bc24-6ddecf542c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training patient IDs\n",
    "train_p_ids = [\n",
    "    \"CID3586\",\n",
    "    \"CID3941\",\n",
    "    \"CID3963\",\n",
    "    \"CID44041\",\n",
    "    \"CID4530N\",\n",
    "    \"CID3838\",\n",
    "    \"CID3946\",\n",
    "    \"CID4040\",\n",
    "    \"CID4461\",\n",
    "    \"CID44991\",\n",
    "    \"CID45171\",\n",
    "    \"CID4535\",\n",
    "    \"CID3948\",\n",
    "    \"CID4398\",\n",
    "    \"CID4463\",\n",
    "    \"CID4495\",\n",
    "    \"CID4513\",\n",
    "    \"CID4465\",\n",
    "]\n",
    "# Training patient IDs\n",
    "test_p_ids = [\n",
    "    \"CID4067\",\n",
    "    \"CID4290A\",\n",
    "    \"CID4471\",\n",
    "    \"CID3921\",\n",
    "    \"CID4066\",\n",
    "    \"CID4523\",\n",
    "    \"CID44971\",\n",
    "    \"CID4515\",\n",
    "]\n",
    "# Cell types\n",
    "c_types = [\n",
    "    \"B-cells\",\n",
    "    \"CAFs\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"Myeloid\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "    \"T-cells\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1a0da77",
   "metadata": {},
   "source": [
    "## 1. Load single-cell and bulk counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3734136a",
   "metadata": {},
   "source": [
    "#### Load single-cell counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw counts\n",
    "sc_adata = adata.read_h5ad(\n",
    "    Path(prefix).joinpath(\"data/filtered/intersect/scRNA_ref_raw.h5ad\")\n",
    ")\n",
    "sc_df = sc_adata.to_df()\n",
    "\n",
    "# Counts-per-10,000 counts\n",
    "normalized_sc_adata = sc.read_h5ad(\n",
    "    Path(prefix).joinpath(\"data/filtered/intersect/scRNA_ref_normalized.h5ad\")\n",
    ")\n",
    "normalized_sc_df = normalized_sc_adata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a683c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pre-filtered metadata file to remove cells type with count < 10 per patient\n",
    "# Load pre-filtered metadata and filter sc_df and normalized_sc_df based on it\n",
    "# First load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/Whole_miniatlas_meta_9_10.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]\n",
    "\n",
    "# Filter counts and metadata\n",
    "train_sc_df = sc_df.loc[train_meta_df.index, :].copy()\n",
    "train_normalized_sc_df = normalized_sc_df.loc[train_meta_df.index, :].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "278b7627",
   "metadata": {},
   "source": [
    "#### Load TCGA bulk counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw counts\n",
    "tcga_raw_counts_df = pd.read_csv(\n",
    "    Path(project_prefix).joinpath(\"data/filtered/intersect/tcga_raw_counts.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# TPM counts\n",
    "tcga_tpm_counts_df = pd.read_csv(\n",
    "    Path(project_prefix).joinpath(\"data/filtered/intersect/tcga_tpm_counts.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc4e3096",
   "metadata": {},
   "source": [
    "## 2. Prepare single-cell reference for each method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a11ece1a-ed29-4bcb-88d0-eeb7c81b1c22",
   "metadata": {},
   "source": [
    "#### CIBERSORTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c72822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert major cell type mapping into dict\n",
    "major_ctype_mapping = {\n",
    "    row[0]: row[1] for i, row in train_meta_df[[\"cell_labels\"]].reset_index().iterrows()\n",
    "}\n",
    "# Replace cell ids with cell types\n",
    "cbx_sc_df = train_normalized_sc_df.T.rename(columns=major_ctype_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output beautifully\n",
    "cbx_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/deconv/cbx/scRNA_ref.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    chunksize=5000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f8c67e1-2627-48e0-afd9-313e7da7cc02",
   "metadata": {},
   "source": [
    "#### Scaden\n",
    "We use simulated mixtures generated for the matching pseudobulk project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b55326-0689-4919-b9f2-41682c291bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix to scaden data folder in the matching pseudobulk project\n",
    "pseudobulk_prefix = (\n",
    "    \"???/01_purity_levels_experiment/include_normal_epithelial/data/scaden\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de650c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train AnnData object\n",
    "scaden_train_adata = adata.read_h5ad(\n",
    "    Path(pseudobulk_prefix).joinpath(\"train_counts.h5ad\")\n",
    ")\n",
    "scaden_train_df = scaden_train_adata.to_df()\n",
    "\n",
    "# Load hugo-ensembl mapping\n",
    "hugo_ensembl_mapping_df = pd.read_csv(\n",
    "    Path(project_prefix).joinpath(\"data/raw/hugo_ensembl_maps.tsv\"),\n",
    "    header=None,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "hugo_ensembl_mapping_df.columns = [\"gene_symbol\", \"ensembl_id\"]\n",
    "hugo_ensembl_mapping_d = {\n",
    "    i[1][\"gene_symbol\"]: i[1][\"ensembl_id\"] for i in hugo_ensembl_mapping_df.iterrows()\n",
    "}\n",
    "\n",
    "# Replace gene_symbol with ensembl_id in scaden_train_df\n",
    "scaden_train_df.rename(columns=hugo_ensembl_mapping_d, inplace=True)\n",
    "\n",
    "# Only keep ensembl genes that exist in filtered single-cell dataframe\n",
    "filtered_scaden_train_df = scaden_train_df[sc_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save filtered AnnData object\n",
    "filtered_train_adata = adata.AnnData(\n",
    "    X=filtered_scaden_train_df.values,\n",
    "    obs=scaden_train_adata.obs.copy(),\n",
    "    var=filtered_scaden_train_df.columns.to_frame().rename(\n",
    "        columns={\"index\": \"ensembl_id\"}\n",
    "    ),\n",
    "    dtype=\"float64\",\n",
    ")\n",
    "\n",
    "# Scaden requires cell fractions DataFrame to have a column call \"ds\"\n",
    "# This column is supposed to store info on what dataset each row comes from\n",
    "# And the during training we can delect which dataset gets used for training, which is quite handy\n",
    "# However, in this case, there is only 1 dataset\n",
    "# Make all row ds=\"Swarbrick_GSE176078\"\n",
    "filtered_train_adata.obs[\"ds\"] = \"Swarbrick_GSE176078\"\n",
    "\n",
    "# add cell types and signature genes\n",
    "filtered_train_adata.uns[\"cell_types\"] = c_types\n",
    "\n",
    "# Rename index and columns properly\n",
    "filtered_train_adata.obs.index.name = \"mixture_id\"\n",
    "filtered_train_adata.var.index.name = None\n",
    "\n",
    "# Save AnnData object\n",
    "filtered_train_adata.write_h5ad(f\"{prefix}/data/deconv/scaden/train_counts.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adbd1a1e",
   "metadata": {},
   "source": [
    "#### CPM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1c2f78f",
   "metadata": {},
   "source": [
    "For CPM, we need to prepare 3 files (in addition to bulk counts):\n",
    "- single-cell reference:    rows as genes, columns as cells\n",
    "- cell labels:              one single column with cell labels\n",
    "- UMAP/tSNE:                first column is cell labels, next 2 columns are UMAP/tSNE coordinates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60a5c82c",
   "metadata": {},
   "source": [
    "#### UMAP coordinates\n",
    "CPM requires the cell state space to be dense and smooth, as well as able to reflect the phenotype of cells and capture the essence of gene-regulation variation among the reference single cells. One way to generate such cell-state space is via the use of dimensionality reduction techniques such as tSNE or UMAP.\n",
    "\n",
    "Wu et al has done exceptional work in integrating single cells from 26 patients and across 3 different molecular subtypes in their dimensional reduction analysis. This abundance of cells from multiple subjects and subtypes resulted in a very dense and smooth distributions of cells in 2-dimensional space. We took advantages of the UMAP coordinates from this analysis, filtered out cells from test patients, i.e. those used for simulated text bulk mixtures. UMAP coordinates from the retained cells (i.e. cells from training patients) were used as cell-state space for UMAP.\n",
    "\n",
    "Moreover, we attempted at re-running Wu et al's dimensional reduction pipeline on only cells from training patients and produced very similar UMAP distributions compared to the original UMAP coordinates. On the other hand, CPM's requirements for the cell-state space suggests that the quality of this space can benefit from larger and more diverse cells. For these two reasons, we chose to employ the original UMAP coordinates provided by Wu et al. (after cells from test patients are filtered out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032da49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all manifold coordinates created by Wu etl\n",
    "umap_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_umap.coords.tsv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Drop second row which contains datatype\n",
    "umap_df.drop([\"TYPE\"], axis=0, inplace=True)\n",
    "umap_df = umap_df.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c40af25b",
   "metadata": {},
   "source": [
    "#### Random sample 1,330 cells for each cell type\n",
    "- We have 59,680 single cells in the training data\n",
    "- With CPM's settings, and with the way we parallelize the execution into 19 partitions, each partition will take ~30hours to finish\n",
    "- There are only 3 machines in HPC that can help us achieve this performance\n",
    "- So **30h * 19 = 570h** in totals. Split across 3 machines, ie. **570 / 3 = 190h**, or 8 days to finish one run (given we can have these 3 nodes unteruptedly for 8 days)\n",
    "- This is why current results are being generated using only 11,969 cells (i.e. 1,329 cells per type). The full run is still being processed while we push ahead with drafting the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First random sample 1,330 cells from each type\n",
    "l = []\n",
    "\n",
    "for c_type in tqdm(c_types):\n",
    "    subset_train_meta_df = train_meta_df[train_meta_df[\"cell_labels\"] == c_type]\n",
    "    l.append(subset_train_meta_df.sample(n=1329, random_state=41))\n",
    "\n",
    "sampled_train_meta_df = pd.concat(l, axis=0)\n",
    "sampled_cell_ids = sampled_train_meta_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter single cell labels\n",
    "sampled_sc_labels_df = sampled_train_meta_df.sort_index()[\"cell_labels\"].to_frame()\n",
    "\n",
    "# Filter single cell labels\n",
    "sampled_umap_df = umap_df[umap_df.index.isin(sampled_cell_ids)].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df349097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cell ids to filter counts data\n",
    "cpm_sc_df = (\n",
    "    train_normalized_sc_df[train_normalized_sc_df.index.isin(sampled_cell_ids)]\n",
    "    .sort_index()\n",
    "    .T\n",
    ")\n",
    "\n",
    "# Add cell types to single cell reference matrix columns\n",
    "cpm_sc_df.columns = (\n",
    "    meta_df[meta_df.index.isin(cpm_sc_df.T.index)][\"cell_labels\"].sort_index().values\n",
    "    + \"_\"\n",
    "    + cpm_sc_df.T.index.values\n",
    ")\n",
    "cpm_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d59391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this save function if we are using original cell-state from Wu et al and only 1,330 cells per type\n",
    "experiment = \"expr_2_original_cellstate_1330_per_ctype\"\n",
    "\n",
    "sampled_sc_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/single_cell_label.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "sampled_umap_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/cell_state.csv\"), sep=\",\"\n",
    ")\n",
    "\n",
    "cpm_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/scRNA_ref_1330_per_ctype.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    chunksize=1000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7743db9",
   "metadata": {},
   "source": [
    "#### bisque\n",
    "bisque expect a .h5ad file holding non-logs single-cell gene counts in the bique/ folder <br>\n",
    "This file would have been previously generated for CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patieint id, cell labels and cell ids into a phenotype DataFrame\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].reset_index()\n",
    "pheno_df.columns = [\"cell_ids\", \"patient_ids\", \"cell_labels\"]\n",
    "\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/deconv/bisque/phenotypes.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df3d16d",
   "metadata": {},
   "source": [
    "#### We're using scaled non-logged counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "bisque_sc_df = train_normalized_sc_df.T[pheno_df[\"cell_ids\"].values].copy()\n",
    "\n",
    "# Normalize data\n",
    "mms = pp.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "bisque_scaled_sc_arr = mms.fit_transform(bisque_sc_df.T).T\n",
    "bisque_scaled_sc_df = pd.DataFrame(\n",
    "    bisque_scaled_sc_arr, index=bisque_sc_df.index, columns=bisque_sc_df.columns\n",
    ")\n",
    "\n",
    "# Save scaled linear counts\n",
    "bisque_scaled_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bisque/scaled_scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dacbd32",
   "metadata": {},
   "source": [
    "#### DWLS\n",
    "DWLS only expects single cell labels accompanying the single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\"]].sort_index()\n",
    "\n",
    "# Apparently R/3.5.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/3.5.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Normal Epithelial\": \"Normal_Epithelial\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/dwls/single_cell_labels.csv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "dwls_sc_df = train_normalized_sc_df.T[labels_df.index].copy()\n",
    "\n",
    "dwls_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/dwls/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8ab4ca7",
   "metadata": {},
   "source": [
    "#### EPIC\n",
    "EPIC relies on the signature matrix and marker genes generated by CIBERSORTx to run <br>\n",
    "This processing script assumes that these 2 files have already been put in the data/epic folders\n",
    "- Signature matrix (containing all genes): cbx_sig_matrix.txt\n",
    "- Marker genes (a subset of signature matrix): cbx_sig_matrix.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signature matrix and marker genes profiles\n",
    "cbx_sig_matrix_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/epic/cbx_sig_matrix/cbx_sig_matrix.txt\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# EPIC assumes the \"unknown\" cells in a tumour is cancer cells\n",
    "# Therefore we need to drop Cancer Epithelial from the signature matrix\n",
    "cbx_sig_matrix_df.drop([\"Cancer Epithelial\"], axis=1, inplace=True)\n",
    "\n",
    "# Save signature matrix beautifully\n",
    "cbx_sig_matrix_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/epic/cbx_sig_matrix/reference_profiles.csv\"),\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# Extract marker genes from marker gene profiles and save into a .csv\n",
    "marker_gene_labels_df = (\n",
    "    cbx_sig_matrix_df.index.to_frame()\n",
    "    .rename(columns={\"GeneSymbol\": \"gene_symbol\"})\n",
    "    .reset_index()\n",
    "    .drop([\"GeneSymbol\"], axis=1)\n",
    ")\n",
    "\n",
    "marker_gene_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/epic/cbx_sig_matrix/marker_gene_symbols.csv\"),\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b521257f",
   "metadata": {},
   "source": [
    "#### hspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44952f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log1p (i.e. add 1 and apply log2)\n",
    "# hspe only mentions log2 without + 1. This will lead to undefined output, as log2(0) = infinity. We therefore added 1 to gene expressions to avoid this\n",
    "# 0 gene expression values will stil return 0 after log1p transformation\n",
    "hspe_sc_df = np.log2(train_normalized_sc_df + 1)\n",
    "\n",
    "# Rename index\n",
    "hspe_sc_df.columns.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log1p one TCGA TPM counts\n",
    "hspe_test_counts_df = np.log2(tcga_tpm_counts_df.T + 1)\n",
    "hspe_test_counts_df.columns.name = \"gene_symbol\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc44b5e",
   "metadata": {},
   "source": [
    "##### Save train & test counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56504c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving train and test counts , do a sanity check to make sure train and test DataFrames have the same genes in the same order\n",
    "assert np.array_equal(\n",
    "    hspe_test_counts_df.columns.to_numpy(), hspe_test_counts_df.columns.to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9da2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell datta\n",
    "hspe_sc_df.to_csv(Path(prefix).joinpath(\"data/deconv/hspe/scRNA_ref.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split TCGA data into 10 shards\n",
    "# This allows us to paralellize the run into 190-fold\n",
    "for shard in tqdm(list(range(0, 20, 1))):\n",
    "    shard_hspe_test_counts_df = np.array_split(hspe_test_counts_df, 20)[shard]\n",
    "\n",
    "    shard_hspe_test_counts_df.to_csv(\n",
    "        Path(prefix).joinpath(f\"data/deconv/hspe/logged_test_counts_{shard}.txt\"),\n",
    "        sep=\"\\t\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ec3ca82",
   "metadata": {},
   "source": [
    "##### Extract pure samples\n",
    "Both dtangle and hspe require a pure_samples variable. This is a list variable, in which each item corresponds to one cell type and indexes of all cells of the same type in the single-cell reference DataFrame <br>\n",
    "\n",
    "We need to retrieve cell type of the single-cell reference data and save this information into a .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of log_train_sc_df() so we have order of cell ids as the indexes\n",
    "reset_hspe_sc_df = hspe_sc_df.reset_index().rename(columns={\"NAME\": \"cell_ids\"})\n",
    "\n",
    "# Iterate over cell types and extract cell indexes from single-cell reference\n",
    "pure_samples_d = {}\n",
    "\n",
    "for c_type in tqdm(train_meta_df[\"cell_labels\"].unique()):\n",
    "    c_ids = (train_meta_df[train_meta_df[\"cell_labels\"] == c_type]).index.tolist()\n",
    "    c_indexes = reset_hspe_sc_df[reset_hspe_sc_df[\"cell_ids\"].isin(c_ids)].index\n",
    "\n",
    "    # Python starts indexes from 0 and R starts from 1\n",
    "    # Add 1 to index and add to pure_samples_d\n",
    "    pure_samples_d[c_type] = (c_indexes + 1).tolist()\n",
    "\n",
    "# Remap keys containing spaces and hyphens\n",
    "pure_samples_d[\"T_cells\"] = pure_samples_d.pop(\"T-cells\")\n",
    "pure_samples_d[\"B_cells\"] = pure_samples_d.pop(\"B-cells\")\n",
    "pure_samples_d[\"Normal_Epithelial\"] = pure_samples_d.pop(\"Normal Epithelial\")\n",
    "pure_samples_d[\"Cancer_Epithelial\"] = pure_samples_d.pop(\"Cancer Epithelial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pure_samples_d into a json file\n",
    "json.dump(\n",
    "    pure_samples_d,\n",
    "    open(Path(prefix).joinpath(f\"data/deconv/hspe/pure_samples.json\"), \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "337f5d7d",
   "metadata": {},
   "source": [
    "### 8. MuSiC\n",
    "MuSiC requires single-cell and bulk expressions in ExpressionSet objects <br>\n",
    "The single-cell ExpressionSet also needs to a phenoType item containing\n",
    "- **sampleID**        index of patient\n",
    "- **SubjectName**      patient id\n",
    "- **cellTypeID**       index of cell type\n",
    "- **cellType**         cell annotation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename index\n",
    "music_sc_df = train_normalized_sc_df.T.copy()\n",
    "music_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"Patient\" + \"celltype_major columns\" and rename columns to match MuSiC requirements\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].rename(\n",
    "    columns={\"Patient\": \"SubjectName\", \"cell_labels\": \"cellType\"}\n",
    ")\n",
    "\n",
    "pheno_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69176b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode cell labels into number to use as cellTypeID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(c_types)\n",
    "pheno_df[\"cellTypeID\"] = l_encoder.transform(pheno_df[\"cellType\"]) + 1\n",
    "\n",
    "# Encode patient ids into number to use as sampleID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(pheno_df[\"SubjectName\"].unique())\n",
    "pheno_df[\"sampleID\"] = l_encoder.transform(pheno_df[\"SubjectName\"]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pheno DataFrame\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/deconv/music/pheno.csv\"), sep=\"\\t\")\n",
    "\n",
    "# Save train counts\n",
    "music_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/music/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "096beb28",
   "metadata": {},
   "source": [
    "### 9. BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99392c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train single-cell to bprism_sc_df\n",
    "bprism_sc_df = train_normalized_sc_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\", \"celltype_minor\"]]\n",
    "\n",
    "# Apparently R/4.2.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/4.2.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "        \"Normal Epithelial\": \"Normal_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "labels_df[\"celltype_minor\"].replace(\n",
    "    {\n",
    "        \"Endothelial ACKR1\": \"Endothelial_ACKR1\",\n",
    "        \"Endothelial RGS5\": \"Endothelial_RGS5\",\n",
    "        \"Endothelial CXCL12\": \"Endothelial_CXCL12\",\n",
    "        \"CAFs MSC iCAF-like\": \"CAFs_MSC_iCAF-like\",\n",
    "        \"CAFs myCAF-like\": \"CAFs_myCAF_like\",\n",
    "        \"PVL Differentiated\": \"PVL_Differentiated\",\n",
    "        \"PVL Immature\": \"PVL_Immature\",\n",
    "        \"Endothelial Lymphatic LYVE1\": \"Endothelial_Lymphatic_LYVE1\",\n",
    "        \"B cells Memory\": \"B_cells_Memory\",\n",
    "        \"B cells Naive\": \"B_cells_Naive\",\n",
    "        \"T cells CD8+\": \"T_cells_CD8\",\n",
    "        \"T cells CD4+\": \"T_cells_CD4\",\n",
    "        \"NK cells\": \"NK_cells\",\n",
    "        \"Cycling T-cells\": \"Cycling_T_cells\",\n",
    "        \"NKT cells\": \"NKT_cells\",\n",
    "        \"Luminal Progenitors\": \"Luminal_Progenitors\",\n",
    "        \"Mature Luminal\": \"Mature_Luminal\",\n",
    "        \"Cycling PVL\": \"Cycling_PVL\",\n",
    "        \"Cancer LumB SC\": \"Cancer_LumB_SC\",\n",
    "        \"Cancer Cycling\": \"Cancer_Cycling\",\n",
    "        \"Cancer LumA SC\": \"Cancer_LumA_SC\",\n",
    "        \"Cancer Basal SC\": \"Cancer_Basal_SC\",\n",
    "        \"Cancer Her2 SC\": \"Cancer_Her2_SC\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Rename column\n",
    "labels_df.rename(\n",
    "    columns={\"cell_labels\": \"cell_type_labels\", \"celltype_minor\": \"cell_state_labels\"},\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell counts and labels\n",
    "labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/bprism/single_cell_labels.csv\"), sep=\"\\t\"\n",
    ")\n",
    "bprism_v2_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/deconv/bprism/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
