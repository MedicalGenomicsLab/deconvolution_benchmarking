{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7cc55-3b46-46c2-bdd6-6e34ffdc37f1",
   "metadata": {},
   "source": [
    "# Collate model predictions from purity-level partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a63a1-8e52-493c-b685-5a419fa97191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as adata\n",
    "import scanpy as sc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly as plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cef7f-433e-4db0-8f5f-942d374522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/include_normal_epithelial\"\n",
    "purity_levels = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "c_types = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"T-cells\",\n",
    "    \"B-cells\",\n",
    "    \"Myeloid\",\n",
    "    \"Endothelial\",\n",
    "    \"CAFs\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0976ba6",
   "metadata": {},
   "source": [
    "## Prepare our groundtruth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42dd16",
   "metadata": {},
   "source": [
    "If we haven't extracted groundtruth from test AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "truth_df = test_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "truth_df = truth_df[c_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a983bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results/ directory if it hasn't existed yet\n",
    "Path(prefix).joinpath(\"data/results/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into csv beautifully\n",
    "truth_df.to_csv(Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcfd27",
   "metadata": {},
   "source": [
    "If we have already extracted the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562086a-5077-43a2-989e-422ee88109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load truth.csv\n",
    "truth_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "truth_df.columns = c_types\n",
    "truth_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcc9c0-de70-498e-9bf9-d677e877a119",
   "metadata": {},
   "source": [
    "### CIBERSORTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we run in normal mode, the results file is called CIBERSORTx_Results\n",
    "# If we run in Smode or Bmode, the results file will be called CIBERSORTx_Adjusted.txt\n",
    "# Adjust the filename accordingy\n",
    "results_f = \"CIBERSORTx_Results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ec1b6-6624-4277-9bb5-7f50f2d348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cbx/results/{pur_lvl}/{results_f}\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_preds_df.drop([\"P-value\", \"Correlation\", \"RMSE\"], axis=1, inplace=True)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae072859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/cbx.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4b1f2-ef03-4f8f-a5de-3da2884fc6cd",
   "metadata": {},
   "source": [
    "### Scaden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223be65-2e97-4cb4-92ea-bf5621cc7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/scaden/{pur_lvl}/results_{pur_lvl}.txt\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e25770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/scaden.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb013ab5-c4d4-4556-baaf-93229c915b70",
   "metadata": {},
   "source": [
    "### EPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(\n",
    "            f\"data/epic/cbx_sig_matrix/results/{pur_lvl}/results.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Replace otherCells in predictions by Cancer Epithelial\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"otherCells\": \"Cancer Epithelial\",\n",
    "            \"B.cells\": \"B-cells\",\n",
    "            \"T.cells\": \"T-cells\",\n",
    "            \"Normal.Epithelial\": \"Normal Epithelial\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/epic.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5b216",
   "metadata": {},
   "source": [
    "### CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which experiments we'd like to generate results for\n",
    "experiment = \"expr_1_original_cellstate_1330_per_ctype\"\n",
    "\n",
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cpm/{experiment}/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c642862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/cpm.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9ce78",
   "metadata": {},
   "source": [
    "### bisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14da92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bisque/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Get correct groundtruth subset\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bisque.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60dd49",
   "metadata": {},
   "source": [
    "### DWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/dwls/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"T_cells\": \"T-cells\",\n",
    "            \"B_cells\": \"B-cells\",\n",
    "            \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/dwls.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699990e",
   "metadata": {},
   "source": [
    "## MuSiC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/music/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d58b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/music.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ce88",
   "metadata": {},
   "source": [
    "## hspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Iterate over each of the 20 partitions\n",
    "    for partition in list(range(0, 20, 1)):\n",
    "        # Read and reorganize  index and columns to match truth_df\n",
    "        subset_preds_df = pd.read_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/results/{pur_lvl}/{partition}/results.csv\"\n",
    "            ),\n",
    "            sep=\",\",\n",
    "            index_col=0,\n",
    "        )\n",
    "\n",
    "        # Fix up column names\n",
    "        subset_preds_df.rename(\n",
    "            columns={\n",
    "                \"T_cells\": \"T-cells\",\n",
    "                \"B_cells\": \"B-cells\",\n",
    "                \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "                \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        preds_l.append(subset_preds_df)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "\n",
    "# Calcuate preds-truth for each purity level\n",
    "avg_diff_l = []\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_preds_df = preds_df[preds_df.index.isin(subset_truth_df.index)]\n",
    "\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8544ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/hspe.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db86c70",
   "metadata": {},
   "source": [
    "## BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bprism/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"T_cells\": \"T-cells\",\n",
    "            \"B_cells\": \"B-cells\",\n",
    "            \"Normal_Epithelial\": \"Normal Epithelial\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bprism.csv\"), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
