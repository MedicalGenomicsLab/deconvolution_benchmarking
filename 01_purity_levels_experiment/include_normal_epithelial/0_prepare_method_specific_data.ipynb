{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36abf93-9948-47fb-bad3-93aba6d06df9",
   "metadata": {},
   "source": [
    "# Prepare training and test data for specific tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd736f3-3757-4f80-a2a8-bfede8929326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as adata\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a483-c2d7-42fa-af67-8452637f6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/include_normal_epithelial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9580-601c-4e92-bc24-6ddecf542c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training patient IDs\n",
    "train_p_ids = [\n",
    "    \"CID3586\",\n",
    "    \"CID3941\",\n",
    "    \"CID3963\",\n",
    "    \"CID44041\",\n",
    "    \"CID4530N\",\n",
    "    \"CID3838\",\n",
    "    \"CID3946\",\n",
    "    \"CID4040\",\n",
    "    \"CID4461\",\n",
    "    \"CID44991\",\n",
    "    \"CID45171\",\n",
    "    \"CID4535\",\n",
    "    \"CID3948\",\n",
    "    \"CID4398\",\n",
    "    \"CID4463\",\n",
    "    \"CID4495\",\n",
    "    \"CID4513\",\n",
    "    \"CID4465\",\n",
    "]\n",
    "\n",
    "# Training patient IDs\n",
    "test_p_ids = [\n",
    "    \"CID4067\",\n",
    "    \"CID4290A\",\n",
    "    \"CID4471\",\n",
    "    \"CID3921\",\n",
    "    \"CID4066\",\n",
    "    \"CID4523\",\n",
    "    \"CID44971\",\n",
    "    \"CID4515\",\n",
    "]\n",
    "\n",
    "# 19 tumour purity levels: [5%,95%,10%]\n",
    "pur_lvls = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "\n",
    "# 9 major cell types\n",
    "c_types = [\n",
    "    \"B-cells\",\n",
    "    \"CAFs\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"Myeloid\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "    \"T-cells\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450741b8",
   "metadata": {},
   "source": [
    "## 0. Process simulated test mixtures\n",
    "- Grab the .h5ad file containing all test mixture we previously generated \n",
    "- Also save it into partitions corresponding to purity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up test mixture AnnData object\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs.copy()\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test simulate mixtures into purity-level-specific txt files\n",
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_test_counts_df = test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    subset_test_counts_df.T.to_csv(\n",
    "        Path(prefix).joinpath(f\"data/test/test_counts_{pur_lvl}_pur_lvl.txt\"), sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ece1a-ed29-4bcb-88d0-eeb7c81b1c22",
   "metadata": {},
   "source": [
    "## 1. CIBERSORTx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df4250-6e46-4c54-a82a-af1143a6d1f6",
   "metadata": {},
   "source": [
    "#### Prepare scRNA-Seq training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad1c01",
   "metadata": {},
   "source": [
    "CBX requires a single-cell reference matrix with cell labels as columns and gene symbols as rows <br>\n",
    "train_sc_df already has cell ids as columns, we just need to replace this by cell labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ddcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make very sure that cell ids in train_sc_df and train_sc_adata.var are in the same order\n",
    "assert np.array_equal(\n",
    "    train_sc_df.columns.values, train_sc_adata.var[\"cell_labels\"].index.values\n",
    ")\n",
    "\n",
    "# Then simply replace columns with cell labels\n",
    "train_sc_df.columns = train_sc_adata.var[\"cell_labels\"].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c72822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for CBX first if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/cbx/\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save output beautifully\n",
    "train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/cbx/scRNA_ref.txt\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c67e1-2627-48e0-afd9-313e7da7cc02",
   "metadata": {},
   "source": [
    "## 2. Scaden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a4f2f-21f8-42f4-9367-c704ca3f2792",
   "metadata": {},
   "source": [
    "#### Prepare AnnData training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the anndata files that have been prepared in previous steps\n",
    "train_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/training_sim_mixts.h5ad\"))\n",
    "train_counts_df = train_adata.to_df()\n",
    "train_labels_df = train_adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b01890-6639-4340-ab11-a16c716eab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First remove \"batch\" column in obs and replace NaN by 0\n",
    "scaden_train_adata = train_adata.copy()\n",
    "scaden_train_adata.obs = scaden_train_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "\n",
    "# Scaden requires cell fractions DataFrame to have a column call \"ds\"\n",
    "# This column is supposed to store info on what dataset each row comes from\n",
    "# And the during training we can delect which dataset gets used for training, which is quite handy\n",
    "# However, in this case, there is only 1 dataset\n",
    "# Make all row ds=\"Wu_et_al_GSE176078\"\n",
    "scaden_train_adata.obs[\"ds\"] = \"Wu_et_al_GSE176078\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257f042-547b-402a-83c0-6157787694e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cell types and signature genes\n",
    "scaden_train_adata.uns[\"cell_types\"] = [\n",
    "    \"T-cells\",\n",
    "    \"B-cells\",\n",
    "    \"Myeloid\",\n",
    "    \"CAFs\",\n",
    "    \"Plasmablasts\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"PVL\",\n",
    "]\n",
    "scaden_train_adata.uns[\"unknown\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename index and columns properly\n",
    "scaden_train_adata.obs.index.name = \"mixture_id\"\n",
    "scaden_train_adata.var.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b55326-0689-4919-b9f2-41682c291bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for Scaden first if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/scaden/\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save training data beautifully\n",
    "scaden_train_adata.write_h5ad(Path(prefix).joinpath(\"data/scaden/train_counts.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd1a1e",
   "metadata": {},
   "source": [
    "## 3. CPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2f78f",
   "metadata": {},
   "source": [
    "For CPM, we need to prepare 3 files (in addition to bulk counts):\n",
    "- single-cell reference:    rows as genes, columns as cells\n",
    "- cell labels:              one single column with cell labels\n",
    "- UMAP/tSNE:                first column is cell labels, next 2 columns are UMAP/tSNE coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbd474",
   "metadata": {},
   "source": [
    "#### Single cell reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_counts_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_counts_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878a59d",
   "metadata": {},
   "source": [
    "#### Single cell labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c116f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5c82c",
   "metadata": {},
   "source": [
    "#### UMAP coordinates\n",
    "CPM requires the cell state space to be dense and smooth, as well as able to reflect the phenotype of cells and capture the essence of gene-regulation variation among the reference single cells. One way to generate such cell-state space is via the use of dimensionality reduction techniques such as tSNE or UMAP.\n",
    "\n",
    "Wu et al has done exceptional work in integrating single cells from 26 patients and across 3 different molecular subtypes in their dimensional reduction analysis. This abundance of cells from multiple subjects and subtypes resulted in a very dense and smooth distributions of cells in 2-dimensional space. We took advantages of the UMAP coordinates from this analysis, filtered out cells from test patients, i.e. those used for simulated text bulk mixtures. UMAP coordinates from the retained cells (i.e. cells from training patients) were used as cell-state space for UMAP.\n",
    "\n",
    "Moreover, we attempted at re-running Wu et al's dimensional reduction pipeline on only cells from training patients and produced very similar UMAP distributions compared to the original UMAP coordinates. On the other hand, CPM's requirements for the cell-state space suggests that the quality of this space can benefit from larger and more diverse cells. For these two reasons, we chose to employ the original UMAP coordinates provided by Wu et al. (after cells from test patients are filtered out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032da49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all manifold coordinates created by Wu etl\n",
    "umap_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_umap.coords.tsv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Drop second row which contains datatype\n",
    "umap_df.drop([\"TYPE\"], axis=0, inplace=True)\n",
    "umap_df = umap_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40af25b",
   "metadata": {},
   "source": [
    "#### Random sample 1,330 cells for each cell type\n",
    "- We have 59,680 single cells in the training data\n",
    "- With CPM's settings, and with the way we parallelize the execution into 19 partitions, each partition will take ~30hours to finish\n",
    "- There are only 3 machines in HPC that can help us achieve this performance\n",
    "- So **30h * 19 = 570h** in totals. Split across 3 machines, ie. **570 / 3 = 190h**, or 8 days to finish one run (given we can have these 3 nodes unteruptedly for 8 days)\n",
    "- This is why current results are being generated using only 11,969 cells (i.e. 1,329 cells per type). The full run is still being processed while we push ahead with drafting the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First random sample 1,330 cells from each type\n",
    "l = []\n",
    "\n",
    "for c_type in c_types:\n",
    "    subset_train_meta_df = train_meta_df[train_meta_df[\"cell_labels\"] == c_type]\n",
    "    l.append(subset_train_meta_df.sample(n=1329, random_state=41))\n",
    "\n",
    "sampled_train_meta_df = pd.concat(l, axis=0)\n",
    "sampled_cell_ids = sampled_train_meta_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter single cell labels\n",
    "sampled_sc_labels_df = sampled_train_meta_df.sort_index()[\"cell_labels\"].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df349097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cell ids to filter counts data\n",
    "all_train_counts_df_transpose = train_sc_counts_df.T\n",
    "sampled_train_counts_df = (\n",
    "    all_train_counts_df_transpose[\n",
    "        all_train_counts_df_transpose.index.isin(sampled_cell_ids)\n",
    "    ]\n",
    "    .sort_index()\n",
    "    .T\n",
    ")\n",
    "\n",
    "# Add cell types to single cell reference matrix columns\n",
    "sampled_train_counts_df.columns = (\n",
    "    meta_df[meta_df.index.isin(sampled_train_counts_df.T.index)][\"cell_labels\"]\n",
    "    .sort_index()\n",
    "    .values\n",
    "    + \"_\"\n",
    "    + sampled_train_counts_df.T.index.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfe09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter umap coordinates\n",
    "sampled_umap_df = umap_df[umap_df.index.isin(sampled_cell_ids)].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d59391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this save function if we are using original cell-state from Wu et al and only 1,330 cells per type\n",
    "experiment = \"expr_1_original_cellstate_1330_per_ctype\"\n",
    "Path(prefix).joinpath(f\"data/cpm/{experiment}\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sampled_sc_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/single_cell_label.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "sampled_train_counts_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/scRNA_ref_1330_per_ctype.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    chunksize=1000,\n",
    ")\n",
    "\n",
    "sampled_umap_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/cell_state.csv\"), sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7743db9",
   "metadata": {},
   "source": [
    "### 4. bisque\n",
    "bisque expect a .h5ad file holding non-logs single-cell gene counts in the bique/ folder <br>\n",
    "This file would have been previously generated for CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95864d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bisque also requires a DataFrame containing cell ids, cell labels, and patient id\n",
    "# All of this information can be extracted from the original metadata csv\n",
    "\n",
    "# First load up all metadata\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736de542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for bisque if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/bisque/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patieint id, cell labels and cell ids into a phenotype DataFrame\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].reset_index()\n",
    "pheno_df.columns = [\"cell_ids\", \"patient_ids\", \"cell_labels\"]\n",
    "\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/bisque/phenotypes.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single-cell data and log it\n",
    "sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "sc_df = sc_adata.to_df()\n",
    "\n",
    "# Apply logarithm and then scale to [0,1]\n",
    "log_sc_df = np.log2(sc_df + 1)\n",
    "mms = pp.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaled_log_sc_arr = mms.fit_transform(log_sc_df.T).T\n",
    "\n",
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "scaled_log_sc_df = pd.DataFrame(\n",
    "    scaled_log_sc_arr, index=log_sc_df.index, columns=log_sc_df.columns\n",
    ")\n",
    "scaled_log_sc_df = scaled_log_sc_df[pheno_df[\"cell_ids\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "scaled_log_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bisque/scaled_logged_scRNA_ref.csv\"),\n",
    "    sep=\"\\t\",\n",
    "    chunksize=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacbd32",
   "metadata": {},
   "source": [
    "### 5. DWLS\n",
    "DWLS only expects single cell labels accompanying the single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load single cell counts\n",
    "sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "sc_df = sc_adata.to_df()\n",
    "\n",
    "# Then load up metadata, select training patient ids, and sort_index\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c49739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for dwls if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/dwls/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\"]].sort_index()\n",
    "\n",
    "# Apparently R/3.5.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/3.5.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Normal Epithelial\": \"Normal_Epithelial\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "labels_df.to_csv(Path(prefix).joinpath(\"data/dwls/single_cell_labels.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "sc_df = sc_df[labels_df.index]\n",
    "\n",
    "sc_df.to_csv(Path(prefix).joinpath(\"data/dwls/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009b9bb",
   "metadata": {},
   "source": [
    "### 6. EPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee68b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for epic if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe59631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPIC relies on the signature matrix and marker genes generated by CIBERSORTx to run\n",
    "# We need to copy the signature matrix generated by CIBERSORT'x first before running EPIC\n",
    "# CIBERSORTx generate its signature matrix using the single-cell reference\n",
    "# => Signature matrices across all tumour purity levels are identical, we just need to pick one for EPIC\n",
    "cbx_sig_mat_f = \"CIBERSORTx_scRNA_ref_inferred_phenoclasses.CIBERSORTx_scRNA_ref_inferred_refsample.bm.K999.txt\"\n",
    "shutil.copy(\n",
    "    Path(prefix).joinpath(f\"data/cbx/results/{pur_lvls[0]}/{cbx_sig_mat_f}\"),\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/cbx_sig_matrix.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signature matrix and marker genes profiles\n",
    "cbx_sig_matrix_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/cbx_sig_matrix.txt\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# EPIC assumes the \"unknown\" cells in a tumour is cancer cells\n",
    "# Therefore we need to drop Cancer Epithelial from the signature matrix\n",
    "cbx_sig_matrix_df.drop([\"Cancer Epithelial\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Save signature matrix beautifully\n",
    "cbx_sig_matrix_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/reference_profiles.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Extract marker genes from marker gene profiles and save into a .csv\n",
    "marker_gene_labels_df = cbx_sig_matrix_df.index.to_frame()\n",
    "marker_gene_labels_df.rename(columns={\"NAME\": \"gene_symbol\"}, inplace=True)\n",
    "\n",
    "marker_gene_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/marker_gene_symbols.csv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521257f",
   "metadata": {},
   "source": [
    "### 7. hspe\n",
    "hspe performs tumour deconvolution by first building a list of marker genes for each cell types. Both methods assume that each cell type has a unique list of marker genes. For each cell type, hspe uses log2-transformed expressions of the cell type's marker genes to deconvolve the cell type's proportion within the mixture using a linear mix equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44952f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\"\n",
    "\n",
    "# Apply log1p (i.e. add 1 and apply log2)\n",
    "# Both dtangle and hspe only mention log2 without + 1. This will lead to undefined output, as log2(0) = infinity. We therefore added 1 to gene expressions to avoid this\n",
    "# 0 gene expression values will stil return 0 after log1p transformation\n",
    "log_train_sc_df = np.log2(train_sc_df + 1)\n",
    "\n",
    "# Also oth dtangle and hspe require bulk mixtures and single-cell reference to have genes as columns and rows as samples. We need to tranpose it\n",
    "log_train_sc_df = log_train_sc_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test count DataFrames and transpose them so genes are columns and samples are rows\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)\n",
    "\n",
    "# Apply log1p one test counts\n",
    "log_test_counts_df = np.log2(test_counts_df + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc44b5e",
   "metadata": {},
   "source": [
    "##### Save train & test counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56504c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving train and test counts , do a sanity check to make sure train and test DataFrames have the same genes in the same order\n",
    "assert np.array_equal(\n",
    "    log_train_sc_df.columns.to_numpy(), log_test_counts_df.columns.to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63645476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for hspe if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/hspe/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data by purity levels\n",
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_test_counts_df = log_test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    # Within each tumour purity, split data into 10 shards\n",
    "    # This allows us to paralellize the run into 190-fold\n",
    "    for shard in tqdm(list(range(0, 20, 1))):\n",
    "        shard_obs_df = np.array_split(subset_obs_df, 20)[shard]\n",
    "        shard_test_counts_df = subset_test_counts_df.loc[shard_obs_df.index, :]\n",
    "\n",
    "        shard_test_counts_df.to_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/logged_test_counts_{pur_lvl}_pur_lvl_{shard}.txt\"\n",
    "            ),\n",
    "            sep=\"\\t\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3ca82",
   "metadata": {},
   "source": [
    "##### Extract pure samples\n",
    "Both dtangle and hspe require a pure_samples variable. This is a list variable, in which each item corresponds to one cell type and indexes of all cells of the same type in the single-cell reference DataFrame <br>\n",
    "\n",
    "We need to retrieve cell type of the single-cell reference data and save this information into a .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94282971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of log_train_sc_df() so we have order of cell ids as the indexes\n",
    "reset_log_train_sc_df = log_train_sc_df.reset_index().rename(\n",
    "    columns={\"index\": \"cell_ids\"}\n",
    ")\n",
    "\n",
    "# Iterate over cell types and extract cell indexes from single-cell reference\n",
    "pure_samples_d = {}\n",
    "\n",
    "for c_type in tqdm(train_meta_df[\"cell_labels\"].unique()):\n",
    "    c_ids = (train_meta_df[train_meta_df[\"cell_labels\"] == c_type]).index.tolist()\n",
    "    c_indexes = reset_log_train_sc_df[\n",
    "        reset_log_train_sc_df[\"cell_ids\"].isin(c_ids)\n",
    "    ].index\n",
    "\n",
    "    # Python starts indexes from 0 and R starts from 1\n",
    "    # Add 1 to index and add to pure_samples_d\n",
    "    pure_samples_d[c_type] = (c_indexes + 1).tolist()\n",
    "\n",
    "# Remap keys containing spaces and hyphens\n",
    "pure_samples_d[\"T_cells\"] = pure_samples_d.pop(\"T-cells\")\n",
    "pure_samples_d[\"B_cells\"] = pure_samples_d.pop(\"B-cells\")\n",
    "pure_samples_d[\"Normal_Epithelial\"] = pure_samples_d.pop(\"Normal Epithelial\")\n",
    "pure_samples_d[\"Cancer_Epithelial\"] = pure_samples_d.pop(\"Cancer Epithelial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pure_samples_d into a json file\n",
    "json.dump(\n",
    "    pure_samples_d,\n",
    "    open(Path(prefix).joinpath(f\"data/hspe/pure_samples.json\"), \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell datta\n",
    "log_train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/hspe/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f5d7d",
   "metadata": {},
   "source": [
    "### 8. MuSiC\n",
    "MuSiC requires single-cell and bulk expressions in ExpressionSet objects <br>\n",
    "The single-cell ExpressionSet also needs to a phenoType item containing\n",
    "- **sampleID**        index of patient\n",
    "- **SubjectName**      patient id\n",
    "- **cellTypeID**       index of cell type\n",
    "- **cellType**         cell annotation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]\n",
    "\n",
    "# Rearrange indexes in meta DF to match order of counts DataFrame\n",
    "train_meta_df = train_meta_df.reindex(train_sc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"Patient\" + \"celltype_major columns\" and rename columns to match MuSiC requirements\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].rename(\n",
    "    columns={\"Patient\": \"SubjectName\", \"cell_labels\": \"cellType\"}\n",
    ")\n",
    "\n",
    "pheno_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69176b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode cell labels into number to use as cellTypeID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(c_types)\n",
    "pheno_df[\"cellTypeID\"] = l_encoder.transform(pheno_df[\"cellType\"]) + 1\n",
    "\n",
    "# Encode patient ids into number to use as sampleID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(pheno_df[\"SubjectName\"].unique())\n",
    "pheno_df[\"sampleID\"] = l_encoder.transform(pheno_df[\"SubjectName\"]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed098ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for music if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/music/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pheno DataFrame\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/music/pheno.csv\"), sep=\"\\t\")\n",
    "\n",
    "# Save train counts\n",
    "train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/music/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096beb28",
   "metadata": {},
   "source": [
    "### 9. BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07614169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_9.csv\"), index_col=0, sep=\"\\t\"\n",
    ")\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]\n",
    "\n",
    "# Rearrange indexes in meta DF to match order of counts DataFrame\n",
    "train_meta_df = train_meta_df.reindex(train_sc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9edcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\"]]\n",
    "\n",
    "# Apparently R/3.5.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/3.5.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "        \"Normal Epithelial\": \"Normal_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f79ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for music if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/bprism/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74be9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell counts and labels\n",
    "labels_df.to_csv(Path(prefix).joinpath(\"data/bprism/single_cell_labels.csv\"), sep=\"\\t\")\n",
    "train_sc_df.T.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bprism/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
