{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b36abf93-9948-47fb-bad3-93aba6d06df9",
   "metadata": {},
   "source": [
    "# Prepare training and test data for specific tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd736f3-3757-4f80-a2a8-bfede8929326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as adata\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a483-c2d7-42fa-af67-8452637f6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/exclude_normal_epithelial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9580-601c-4e92-bc24-6ddecf542c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training patient IDs\n",
    "train_p_ids = [\n",
    "    \"CID3586\",\n",
    "    \"CID3941\",\n",
    "    \"CID3963\",\n",
    "    \"CID44041\",\n",
    "    \"CID4530N\",\n",
    "    \"CID3838\",\n",
    "    \"CID3946\",\n",
    "    \"CID4040\",\n",
    "    \"CID4461\",\n",
    "    \"CID44991\",\n",
    "    \"CID45171\",\n",
    "    \"CID4535\",\n",
    "    \"CID3948\",\n",
    "    \"CID4398\",\n",
    "    \"CID4463\",\n",
    "    \"CID4495\",\n",
    "    \"CID4513\",\n",
    "    \"CID4465\",\n",
    "]\n",
    "\n",
    "# Training patient IDs\n",
    "test_p_ids = [\n",
    "    \"CID4067\",\n",
    "    \"CID4290A\",\n",
    "    \"CID4471\",\n",
    "    \"CID3921\",\n",
    "    \"CID4066\",\n",
    "    \"CID4523\",\n",
    "    \"CID44971\",\n",
    "    \"CID4515\",\n",
    "]\n",
    "\n",
    "# 19 tumour purity levels: [5%,95%,10%]\n",
    "pur_lvls = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "\n",
    "# 8 major cell types (no Normal Epithelial)\n",
    "c_types = [\n",
    "    \"B-cells\",\n",
    "    \"CAFs\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"Myeloid\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "    \"T-cells\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf99e4f1-8d65-482c-8665-d01a6e3130d4",
   "metadata": {},
   "source": [
    "## 0. Process simulated test mixtures\n",
    "- Grab the .h5ad file containing all test mixture we previously generated \n",
    "- Also save it into partitions corresponding to purity levels (which will be used for all tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1450364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up test mixture AnnData object\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs.copy()\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_test_counts_df = test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    subset_test_counts_df.T.to_csv(\n",
    "        Path(prefix).joinpath(f\"data/test/test_counts_{pur_lvl}_pur_lvl.txt\"), sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a11ece1a-ed29-4bcb-88d0-eeb7c81b1c22",
   "metadata": {},
   "source": [
    "## 1. CIBERSORTx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87df4250-6e46-4c54-a82a-af1143a6d1f6",
   "metadata": {},
   "source": [
    "#### Prepare scRNA-Seq training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfdc266e",
   "metadata": {},
   "source": [
    "CBX requires a single-cell reference matrix with cell labels as columns and gene symbols as rows <br>\n",
    "train_sc_df already has cell ids as columns, we just need to replace this by cell labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make very sure that cell ids in train_sc_df and train_sc_adata.var are in the same order\n",
    "assert np.array_equal(\n",
    "    train_sc_df.columns.values, train_sc_adata.var[\"cell_labels\"].index.values\n",
    ")\n",
    "\n",
    "# Then simply replace columns with cell labels\n",
    "train_sc_df.columns = train_sc_adata.var[\"cell_labels\"].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20652008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for CBX first if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/cbx/\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save output beautifully\n",
    "train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/cbx/scRNA_ref.txt\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f8c67e1-2627-48e0-afd9-313e7da7cc02",
   "metadata": {},
   "source": [
    "## 2. Scaden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "970a4f2f-21f8-42f4-9367-c704ca3f2792",
   "metadata": {},
   "source": [
    "#### Prepare AnnData training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b01890-6639-4340-ab11-a16c716eab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the anndata files that have been prepared in previous steps\n",
    "train_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/training_sim_mixts.h5ad\"))\n",
    "train_counts_df = train_adata.to_df()\n",
    "train_labels_df = train_adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First remove \"batch\" column in obs and replace NaN by 0\n",
    "scaden_train_adata = train_adata.copy()\n",
    "scaden_train_adata.obs = scaden_train_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "\n",
    "# Scaden requires cell fractions DataFrame to have a column call \"ds\"\n",
    "# This column is supposed to store info on what dataset each row comes from\n",
    "# And the during training we can delect which dataset gets used for training, which is quite handy\n",
    "# However, in this case, there is only 1 dataset\n",
    "# Make all row ds=\"Wu_et_al_GSE176078\"\n",
    "scaden_train_adata.obs[\"ds\"] = \"Wu_et_al_GSE176078\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257f042-547b-402a-83c0-6157787694e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cell types and signature genes\n",
    "scaden_train_adata.uns[\"cell_types\"] = [\n",
    "    \"T-cells\",\n",
    "    \"B-cells\",\n",
    "    \"Myeloid\",\n",
    "    \"CAFs\",\n",
    "    \"Plasmablasts\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"PVL\",\n",
    "]\n",
    "scaden_train_adata.uns[\"unknown\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename index and columns properly\n",
    "scaden_train_adata.obs.index.name = \"mixture_id\"\n",
    "scaden_train_adata.var.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b55326-0689-4919-b9f2-41682c291bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for Scaden first if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/scaden/\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save training data beautiful\n",
    "scaden_train_adata.write_h5ad(Path(prefix).joinpath(\"data/scaden/train_counts.h5ad\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6926782",
   "metadata": {},
   "source": [
    "### 3. CPM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4516e6db",
   "metadata": {},
   "source": [
    "For CPM, we need to prepare 3 files (in addition to bulk counts):\n",
    "- single-cell reference:    rows as genes, columns as cells\n",
    "- cell labels:              one single column with cell labels\n",
    "- UMAP/tSNE:                first column is cell labels, next 2 columns are UMAP/tSNE coordinates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1094705d",
   "metadata": {},
   "source": [
    "#### Single cell reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the single-cell reference matrix we generated for the with-Normal experiment and remove Normal Epithelial cells\n",
    "with_normal_prefix = \"???/01_purity_levels_experiment/include_normal_epithelial\"\n",
    "experiment = \"expr_2_original_cellstate_1330_per_ctype\"\n",
    "\n",
    "sc_with_normal_df = pd.read_csv(\n",
    "    Path(with_normal_prefix).joinpath(\n",
    "        f\"data/cpm/{experiment}/scRNA_ref_1330_per_ctype.txt\"\n",
    "    ),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e45d6a1",
   "metadata": {},
   "source": [
    "#### UMAP coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49298592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up UMAP nanifold coordinates created by Seurat\n",
    "umap_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_umap.coords.tsv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# Drop second row which contains datatype\n",
    "umap_df.drop([\"TYPE\"], axis=0, inplace=True)\n",
    "umap_df = umap_df.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01a7a237",
   "metadata": {},
   "source": [
    "#### Single cell labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all manifold coordinates created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ba23d63",
   "metadata": {},
   "source": [
    "#### Filter out Normal Epithelial in meta_df to grab cell ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First retrieve indexes of the cells we randomly sampled\n",
    "sampled_cell_ids = [\n",
    "    i.split(\"_\")[1] + \"_\" + i.split(\"_\")[2] for i in sc_with_normal_df.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab these ids in meta_df and umap_df\n",
    "# Filter out Normal Epithelial cells\n",
    "# Then sort_index() to make sure they are in the same order\n",
    "train_meta_without_normal_df = train_meta_df[\n",
    "    (train_meta_df.index.isin(sampled_cell_ids))\n",
    "    & (train_meta_df[\"cell_labels\"] != \"Normal Epithelial\")\n",
    "]\n",
    "\n",
    "# Cell labels\n",
    "sc_without_normal_labels_df = train_meta_without_normal_df.sort_index()[\n",
    "    \"cell_labels\"\n",
    "].to_frame()\n",
    "\n",
    "\n",
    "# UMAP coordinates\n",
    "umap_without_normal_df = umap_df[\n",
    "    umap_df.index.isin(train_meta_without_normal_df.index)\n",
    "].sort_index()\n",
    "\n",
    "# Rearrange columsn in single cell reference data to match order of UMAP and labels DataFrames\n",
    "sc_withouth_normal_df = sc_with_normal_df[\n",
    "    sc_without_normal_labels_df[\"cell_labels\"].values\n",
    "    + \"_\"\n",
    "    + sc_without_normal_labels_df.index.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this save function if we are using original cell-state from Wu et all and only 1,330 cells per type\n",
    "experiment = \"expr_1_original_cellstate_1330_per_ctype\"\n",
    "Path(prefix).joinpath(f\"data/cpm/{experiment}\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sc_without_normal_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/single_cell_label.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "umap_without_normal_df.to_csv(\n",
    "    Path(prefix).joinpath(f\"data/cpm/{experiment}/cell_state.csv\"), sep=\",\"\n",
    ")\n",
    "\n",
    "sc_withouth_normal_df.to_csv(\n",
    "    Path(prefix).joinpath(\n",
    "        f\"data/cpm/{experiment}/scRNA_ref_1330_per_ctype_without_normal.txt\"\n",
    "    ),\n",
    "    sep=\"\\t\",\n",
    "    chunksize=1000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e15f82c",
   "metadata": {},
   "source": [
    "### 4. bisque\n",
    "bisque expect a .h5ad file holding non-logs single-cell gene counts in the bique/ folder <br>\n",
    "This file would have been previously generated for CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803718aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bisque also requires a DataFrame containing cell ids, cell labels, and patient id\n",
    "# All of this information can be extracted from the original metadata csv\n",
    "\n",
    "# First load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# Filter out test patients and Normal Epithelial cells\n",
    "train_meta_df = meta_df[\n",
    "    (meta_df[\"Patient\"].isin(train_p_ids))\n",
    "    & (meta_df[\"cell_labels\"] != \"Normal Epithelial\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b503f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for bisque if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/bisque/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29963715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patieint id, cell labels and cell ids into a phenotype DataFrame\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].reset_index()\n",
    "pheno_df.columns = [\"cell_ids\", \"patient_ids\", \"cell_labels\"]\n",
    "\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/bisque/phenotypes.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca806d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single-cell data and log it\n",
    "sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "sc_df = sc_adata.to_df()\n",
    "\n",
    "# Normalize dataa\n",
    "mms = pp.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaled_sc_arr = mms.fit_transform(sc_df.T).T\n",
    "scaled_sc_df = pd.DataFrame(scaled_sc_arr, index=sc_df.index, columns=sc_df.columns)\n",
    "\n",
    "# Save scaled linear counts\n",
    "scaled_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bisque/scaled_scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b7a6a4",
   "metadata": {},
   "source": [
    "### 5. DWLS\n",
    "DWLS only expects single cell labels accompanying the single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97181c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load single cell counts\n",
    "sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "sc_df = sc_adata.to_df()\n",
    "\n",
    "# Then load up metadata, select training patient ids, and sort_index\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7960d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for dwls if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/dwls/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\"]].sort_index()\n",
    "\n",
    "# Apparently R/3.5.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/3.5.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "labels_df.to_csv(Path(prefix).joinpath(\"data/dwls/single_cell_labels.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d45a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange single-cell DataFrame to match the same order of cell ids as phenotype DataFrame\n",
    "sc_df = sc_df[labels_df.index]\n",
    "\n",
    "sc_df.to_csv(Path(prefix).joinpath(\"data/dwls/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b06c05dd",
   "metadata": {},
   "source": [
    "### 6. EPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for epic if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c914ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPIC relies on the signature matrix and marker genes generated by CIBERSORTx to run\n",
    "# We need to copy the signature matrix generated by CIBERSORT'x first before running EPIC\n",
    "# CIBERSORTx generate its signature matrix using the single-cell reference\n",
    "# => Signature matrices across all tumour purity levels are identical, we just need to pick one for EPIC\n",
    "cbx_sig_mat_f = \"CIBERSORTx_scRNA_ref_inferred_phenoclasses.CIBERSORTx_scRNA_ref_inferred_refsample.bm.K999.txt\"\n",
    "shutil.copy(\n",
    "    Path(prefix).joinpath(f\"data/cbx/results/{pur_lvls[0]}/{cbx_sig_mat_f}\"),\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/cbx_sig_matrix.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd322287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signature matrix and marker genes profiles\n",
    "cbx_sig_matrix_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/cbx_sig_matrix.txt\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# EPIC assumes the \"unknown\" cells in a tumour is cancer cells\n",
    "# Therefore we need to drop Cancer Epithelial from the signature matrix\n",
    "cbx_sig_matrix_df.drop([\"Cancer Epithelial\"], axis=1, inplace=True)\n",
    "\n",
    "# Save signature matrix beautifully\n",
    "cbx_sig_matrix_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/reference_profiles.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Extract marker genes from marker gene profiles and save into a .csv\n",
    "marker_gene_labels_df = cbx_sig_matrix_df.index.to_frame()\n",
    "marker_gene_labels_df.rename(columns={\"NAME\": \"gene_symbol\"}, inplace=True)\n",
    "\n",
    "marker_gene_labels_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/epic/cbx_sig_matrix/marker_gene_symbols.csv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea532758",
   "metadata": {},
   "source": [
    "### 7. hspe\n",
    "hspe performs tumour deconvolution by first building a list of marker genes for each cell types. Both methods assume that each cell type has a unique list of marker genes. For each cell type, hspe uses log2-transformed expressions of the cell type's marker genes to deconvolve the cell type's proportion within the mixture using a linear mix equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\"\n",
    "\n",
    "# Apply log1p (i.e. add 1 and apply log2)\n",
    "# Both dtangle and hspe only mention log2 without + 1. This will lead to undefined output, as log2(0) = infinity. We therefore added 1 to gene expressions to avoid this\n",
    "# 0 gene expression values will stil return 0 after log1p transformation\n",
    "log_train_sc_df = np.log2(train_sc_df + 1)\n",
    "\n",
    "# Also oth dtangle and hspe require bulk mixtures and single-cell reference to have genes as columns and rows as samples. We need to tranpose it\n",
    "log_train_sc_df = log_train_sc_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test count DataFrames and transpose them so genes are columns and samples are rows\n",
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "test_counts_df = test_adata.to_df()\n",
    "test_labels_df = test_adata.obs\n",
    "\n",
    "# Drop the \"batch\" column and fill NaN by 0\n",
    "test_labels_df.drop([\"batch\"], axis=1, inplace=True)\n",
    "test_labels_df.fillna(0, inplace=True)\n",
    "\n",
    "# Apply log1p one test counts\n",
    "log_test_counts_df = np.log2(test_counts_df + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c7795ff",
   "metadata": {},
   "source": [
    "##### Save train & test counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e41237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving train and test counts , do a sanity check to make sure train and test DataFrames have the same genes in the same order\n",
    "assert np.array_equal(\n",
    "    log_train_sc_df.columns.to_numpy(), log_test_counts_df.columns.to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9353dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for hspe if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/hspe/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data by purity levels\n",
    "for pur_lvl in tqdm(pur_lvls):\n",
    "    subset_obs_df = test_labels_df[test_labels_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_test_counts_df = log_test_counts_df.loc[subset_obs_df.index, :]\n",
    "\n",
    "    # Within each tumour purity, split data into 10 shards\n",
    "    # This allows us to paralellize the run into 190-fold\n",
    "    for shard in tqdm(list(range(0, 20, 1))):\n",
    "        shard_obs_df = np.array_split(subset_obs_df, 20)[shard]\n",
    "        shard_test_counts_df = subset_test_counts_df.loc[shard_obs_df.index, :]\n",
    "\n",
    "        shard_test_counts_df.to_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/logged_test_counts_{pur_lvl}_pur_lvl_{shard}.txt\"\n",
    "            ),\n",
    "            sep=\"\\t\",\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0abd8072",
   "metadata": {},
   "source": [
    "##### Extract pure samples\n",
    "Both dtangle and hspe require a pure_samples variable. This is a list variable, in which each item corresponds to one cell type and indexes of all cells of the same type in the single-cell reference DataFrame <br>\n",
    "\n",
    "We need to retrieve cell type of the single-cell reference data and save this information into a .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[\n",
    "    (meta_df[\"Patient\"].isin(train_p_ids))\n",
    "    & (meta_df[\"cell_labels\"] != \"Normal Epithelial\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1674f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of log_train_sc_df() so we have order of cell ids as the indexes\n",
    "reset_log_train_sc_df = log_train_sc_df.reset_index().rename(\n",
    "    columns={\"index\": \"cell_ids\"}\n",
    ")\n",
    "\n",
    "# Iterate over cell types and extract cell indexes from single-cell reference\n",
    "pure_samples_d = {}\n",
    "\n",
    "for c_type in tqdm(train_meta_df[\"cell_labels\"].unique()):\n",
    "    c_ids = (train_meta_df[train_meta_df[\"cell_labels\"] == c_type]).index.tolist()\n",
    "    c_indexes = reset_log_train_sc_df[\n",
    "        reset_log_train_sc_df[\"cell_ids\"].isin(c_ids)\n",
    "    ].index\n",
    "\n",
    "    # Python starts indexes from 0 and R starts from 1\n",
    "    # Add 1 to index and add to pure_samples_d\n",
    "    pure_samples_d[c_type] = (c_indexes + 1).tolist()\n",
    "\n",
    "# Remap keys containing spaces and hyphens\n",
    "pure_samples_d[\"T_cells\"] = pure_samples_d.pop(\"T-cells\")\n",
    "pure_samples_d[\"B_cells\"] = pure_samples_d.pop(\"B-cells\")\n",
    "pure_samples_d[\"Cancer_Epithelial\"] = pure_samples_d.pop(\"Cancer Epithelial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ace76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pure_samples_d into a json file\n",
    "json.dump(\n",
    "    pure_samples_d,\n",
    "    open(Path(prefix).joinpath(f\"data/hspe/pure_samples.json\"), \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell datta\n",
    "log_train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/hspe/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71d3a793",
   "metadata": {},
   "source": [
    "### 8. MuSiC\n",
    "MuSiC requires single-cell and bulk expressions in ExpressionSet objects <br>\n",
    "The single-cell ExpressionSet also needs to a phenoType item containing\n",
    "- **sampleID**        index of patient\n",
    "- **SubjectName**      patient id\n",
    "- **cellTypeID**       index of cell type\n",
    "- **cellType**         cell annotation labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7787942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "train_meta_df = meta_df[\n",
    "    (meta_df[\"Patient\"].isin(train_p_ids))\n",
    "    & (meta_df[\"cell_labels\"] != \"Normal Epithelial\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f706b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"Patient\" + \"celltype_major columns\" and rename columns to match MuSiC requirements\n",
    "pheno_df = train_meta_df[[\"Patient\", \"cell_labels\"]].rename(\n",
    "    columns={\"Patient\": \"SubjectName\", \"cell_labels\": \"cellType\"}\n",
    ")\n",
    "\n",
    "pheno_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb318ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode cell labels into number to use as cellTypeID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(c_types)\n",
    "pheno_df[\"cellTypeID\"] = l_encoder.transform(pheno_df[\"cellType\"]) + 1\n",
    "\n",
    "# Encode patient ids into number to use as sampleID\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(pheno_df[\"SubjectName\"].unique())\n",
    "pheno_df[\"sampleID\"] = l_encoder.transform(pheno_df[\"SubjectName\"]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for music if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/music/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pheno DataFrame\n",
    "pheno_df.to_csv(Path(prefix).joinpath(\"data/music/pheno.csv\"), sep=\"\\t\")\n",
    "\n",
    "# Save train counts\n",
    "train_sc_df = train_sc_df[pheno_df.index]\n",
    "train_sc_df.to_csv(\n",
    "    Path(prefix).joinpath(\"data/music/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99b85e5",
   "metadata": {},
   "source": [
    "### 9. BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd749d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from prepared AnnData object\n",
    "train_sc_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/train/scRNA_ref.h5ad\"))\n",
    "train_sc_df = train_sc_adata.to_df()\n",
    "\n",
    "# Rename index\n",
    "train_sc_df.index.name = \"gene_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46be00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up all metadata created by Seurat\n",
    "meta_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_meta_no_normal.csv\"),\n",
    "    index_col=0,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "train_meta_df = meta_df[meta_df[\"Patient\"].isin(train_p_ids)]\n",
    "\n",
    "# Rearrange indexes in meta DF to match order of counts DataFrame\n",
    "train_meta_df = train_meta_df.reindex(train_sc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c04a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell labels into a DataFrame\n",
    "labels_df = train_meta_df[[\"cell_labels\"]]\n",
    "\n",
    "# Apparently R/3.5.0 doesn't understand how to parse the character \"-\"\n",
    "# meaning \"T-cells\" will be read as a vector of \"T\" and \"cells\"\n",
    "# Also R/3.5.0 can't parse \" \"\n",
    "# Replace all cell types with these characters by \"_\"\n",
    "labels_df[\"cell_labels\"].replace(\n",
    "    {\n",
    "        \"T-cells\": \"T_cells\",\n",
    "        \"B-cells\": \"B_cells\",\n",
    "        \"Cancer Epithelial\": \"Cancer_Epithelial\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make method-specific directory for music if it doesn't exist yet\n",
    "Path(prefix).joinpath(\"data/bprism/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e648fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save single-cell counts and labels\n",
    "labels_df.to_csv(Path(prefix).joinpath(\"data/bprism/single_cell_labels.csv\"), sep=\"\\t\")\n",
    "train_sc_df.T.to_csv(\n",
    "    Path(prefix).joinpath(\"data/bprism/scRNA_ref.csv\"), sep=\"\\t\", chunksize=5000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbfd5e0594ce662354ff192ed6e22a3ed6754bf4a1138f4d535b73aa6171aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
