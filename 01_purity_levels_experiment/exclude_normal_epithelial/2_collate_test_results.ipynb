{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7cc55-3b46-46c2-bdd6-6e34ffdc37f1",
   "metadata": {},
   "source": [
    "# Collate model predictions from purity-level partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a63a1-8e52-493c-b685-5a419fa97191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as adata\n",
    "import scanpy as sc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly as plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cef7f-433e-4db0-8f5f-942d374522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/exclude_normal_epithelial\"\n",
    "purity_levels = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "c_types = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"T-cells\",\n",
    "    \"B-cells\",\n",
    "    \"Myeloid\",\n",
    "    \"Endothelial\",\n",
    "    \"CAFs\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0976ba6",
   "metadata": {},
   "source": [
    "## Prepare our groundtruth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42dd16",
   "metadata": {},
   "source": [
    "If we haven't extracted groundtruth from test AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = sc.read_h5ad(Path(prefix).joinpath(\"data/test/test_sim_mixts.h5ad\"))\n",
    "truth_df = test_adata.obs.drop([\"batch\"], axis=1).fillna(0)\n",
    "truth_df = truth_df[c_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89854e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results/ directory if it hasn't existed yet\n",
    "Path(prefix).joinpath(\"data/results/\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into csv beautifully\n",
    "truth_df.to_csv(Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcfd27",
   "metadata": {},
   "source": [
    "If we have already extracted the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562086a-5077-43a2-989e-422ee88109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load truth.csv\n",
    "truth_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "truth_df.columns = c_types\n",
    "truth_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcc9c0-de70-498e-9bf9-d677e877a119",
   "metadata": {},
   "source": [
    "### CIBERSORTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we run in normal mode, the results file is called CIBERSORTx_Results\n",
    "# If we run in Smode or Bmode, the results file will be called CIBERSORTx_Adjusted.txt\n",
    "# Adjust the filename accordingy\n",
    "results_f = \"CIBERSORTx_Results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ec1b6-6624-4277-9bb5-7f50f2d348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cbx/results/{pur_lvl}/{results_f}\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_preds_df.drop([\"P-value\", \"Correlation\", \"RMSE\"], axis=1, inplace=True)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03de73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/cbx.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4b1f2-ef03-4f8f-a5de-3da2884fc6cd",
   "metadata": {},
   "source": [
    "### Scaden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223be65-2e97-4cb4-92ea-bf5621cc7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/scaden/{pur_lvl}/results_{pur_lvl}.txt\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/scaden.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb013ab5-c4d4-4556-baaf-93229c915b70",
   "metadata": {},
   "source": [
    "### EPIC\n",
    "We're using CBX-derived reference profiles and remove Cancer Epithelial from reference profiles<br>\n",
    "We're treating Other Cells in the output as cancer cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(\n",
    "            f\"data/epic/cbx_sig_matrix/results/{pur_lvl}/results.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Replace otherCells in predictions by Cancer Epithelial\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"otherCells\": \"Cancer Epithelial\",\n",
    "            \"B.cells\": \"B-cells\",\n",
    "            \"T.cells\": \"T-cells\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481802c",
   "metadata": {},
   "source": [
    "#### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/epic.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5b216",
   "metadata": {},
   "source": [
    "### CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which experiments we'd like to generate results for\n",
    "experiment = \"expr_1_original_cellstate_1330_per_ctype/\"\n",
    "\n",
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/cpm/{experiment}/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ea720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/cpm.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9ce78",
   "metadata": {},
   "source": [
    "### bisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14da92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read predictions\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bisque/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Get correct groundtruth subset\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    preds_l.append(subset_preds_df)\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df631aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bisque.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60dd49",
   "metadata": {},
   "source": [
    "### DWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/dwls/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    ).T\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"T_cells\": \"T-cells\",\n",
    "            \"B_cells\": \"B-cells\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae550f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/dwls.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699990e",
   "metadata": {},
   "source": [
    "## MuSiC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/music/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1af930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/music.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ce88",
   "metadata": {},
   "source": [
    "## hspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "\n",
    "    # Iterate over each of the 20 partitions\n",
    "    for partition in list(range(0, 20, 1)):\n",
    "\n",
    "        # Read and reorganize  index and columns to match truth_df\n",
    "        subset_preds_df = pd.read_csv(\n",
    "            Path(prefix).joinpath(\n",
    "                f\"data/hspe/results/{pur_lvl}/{partition}/results.csv\"\n",
    "            ),\n",
    "            sep=\",\",\n",
    "            index_col=0,\n",
    "        )\n",
    "\n",
    "        # Fix up column names\n",
    "        subset_preds_df.rename(\n",
    "            columns={\n",
    "                \"T_cells\": \"T-cells\",\n",
    "                \"B_cells\": \"B-cells\",\n",
    "                \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        preds_l.append(subset_preds_df)\n",
    "\n",
    "preds_df = pd.concat(preds_l, axis=0)\n",
    "\n",
    "# Calcuate preds-truth for each purity level\n",
    "avg_diff_l = []\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "    subset_preds_df = preds_df[preds_df.index.isin(subset_truth_df.index)]\n",
    "\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "    avg_diff_l.append(avg_diff)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/hspe.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac842a",
   "metadata": {},
   "source": [
    "## BayesPrism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de355346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store average of (preds - truth) of each purity levels\n",
    "avg_diff_l = []\n",
    "preds_l = []\n",
    "\n",
    "# Iterate over purity levels\n",
    "for pur_lvl in tqdm(purity_levels):\n",
    "    # Read and reorganize  index and columns to match truth_df\n",
    "    subset_preds_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/bprism/results/{pur_lvl}/results.csv\"),\n",
    "        sep=\",\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Fix up column names\n",
    "    subset_preds_df.rename(\n",
    "        columns={\n",
    "            \"T_cells\": \"T-cells\",\n",
    "            \"B_cells\": \"B-cells\",\n",
    "            \"Cancer_Epithelial\": \"Cancer Epithelial\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    subset_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == pur_lvl]\n",
    "\n",
    "    # Calcuate preds-truth for each purity level\n",
    "    diff_df = abs(subset_preds_df[c_types].sort_index() - subset_truth_df.sort_index())\n",
    "    # diff_df = subset_preds_df[c_types] - subset_truth_df\n",
    "    avg_diff = diff_df.mean().to_frame()\n",
    "    avg_diff.columns = [pur_lvl]\n",
    "\n",
    "    avg_diff_l.append(avg_diff)\n",
    "    preds_l.append(subset_preds_df)\n",
    "\n",
    "avg_diff_df = pd.concat(avg_diff_l, axis=1)\n",
    "preds_df = pd.concat(preds_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds_df.to_csv(Path(prefix).joinpath(\"data/results/bprism.csv\"), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3aa7b5453cf205659044c9f653fe62c424e2f70fe7294eb3079261e6ff67292"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
