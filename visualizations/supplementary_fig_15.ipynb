{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7cc55-3b46-46c2-bdd6-6e34ffdc37f1",
   "metadata": {},
   "source": [
    "# Visualize models performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a63a1-8e52-493c-b685-5a419fa97191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as adata\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly as plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity as skl_cosine\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from math import sqrt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf1eae",
   "metadata": {},
   "source": [
    "## Set up paths and load setting files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a86b11",
   "metadata": {},
   "source": [
    "#### Path to subset/minor/major experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset\n",
    "subset_prefix = (\n",
    "    \"???/deconvolution_benchmarking/03_immune_lineages_experiment/subset_level\"\n",
    ")\n",
    "\n",
    "# Minor\n",
    "minor_prefix = (\n",
    "    \"???/deconvolution_benchmarking/03_immune_lineages_experiment/minor_level\"\n",
    ")\n",
    "\n",
    "# Major\n",
    "major_prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/include_normal_epithelial\"\n",
    "\n",
    "# Prefix to visualizations folder\n",
    "viz_prefix = \"???/deconvolution_benchmarking/visualizations\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40e5e2d3",
   "metadata": {},
   "source": [
    "#### List major/minor/subset cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cef7f-433e-4db0-8f5f-942d374522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_c_types = [\n",
    "    \"Endothelial\",\n",
    "    \"CAFs\",\n",
    "    \"PVL\",\n",
    "    \"B cells Memory\",\n",
    "    \"B cells Naive\",\n",
    "    \"T_cells_c4_CD8+_ZFP36\",\n",
    "    \"T_cells_c6_IFIT1\",\n",
    "    \"T_cells_c7_CD8+_IFNG\",\n",
    "    \"T_cells_c8_CD8+_LAG3\",\n",
    "    \"T_cells_c0_CD4+_CCR7\",\n",
    "    \"T_cells_c1_CD4+_IL7R\",\n",
    "    \"T_cells_c2_CD4+_T-regs_FOXP3\",\n",
    "    \"T_cells_c3_CD4+_Tfh_CXCL13\",\n",
    "    \"T_cells_c9_NK_cells_AREG\",\n",
    "    \"T_cells_c11_MKI67\",\n",
    "    \"T_cells_c10_NKT_cells_FCGR3A\",\n",
    "    \"Myeloid_c10_Macrophage_1_EGR1\",\n",
    "    \"Myeloid_c12_Monocyte_1_IL1B\",\n",
    "    \"Myeloid_c2_LAM2_APOE\",\n",
    "    \"Myeloid_c1_LAM1_FABP5\",\n",
    "    \"Cycling_Myeloid\",\n",
    "    \"Myeloid_c4_DCs_pDC_IRF7\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"Plasmablasts\",\n",
    "    \"Myeloid_c8_Monocyte_2_S100A9\",\n",
    "    \"Myeloid_c9_Macrophage_2_CXCL10\",\n",
    "    \"Myeloid_c11_cDC2_CD1C\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Myeloid_c3_cDC1_CLEC9A\",\n",
    "]\n",
    "minor_c_types = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"T cells CD4+\",\n",
    "    \"T cells CD8+\",\n",
    "    \"Endothelial\",\n",
    "    \"CAFs\",\n",
    "    \"Macrophage\",\n",
    "    \"PVL\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"Plasmablasts\",\n",
    "    \"B cells Memory\",\n",
    "    \"Monocyte\",\n",
    "    \"Cycling_Myeloid\",\n",
    "    \"Cycling T-cells\",\n",
    "    \"NK cells\",\n",
    "    \"NKT cells\",\n",
    "    \"DCs\",\n",
    "    \"B cells Naive\",\n",
    "]\n",
    "major_c_types = [\n",
    "    \"B-cells\",\n",
    "    \"CAFs\",\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Endothelial\",\n",
    "    \"Myeloid\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "    \"T-cells\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090d9bc",
   "metadata": {},
   "source": [
    "#### Load groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use tumour purity = 50%\n",
    "pur_lvl = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562086a-5077-43a2-989e-422ee88109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset\n",
    "subset_truth_df = pd.read_csv(\n",
    "    Path(subset_prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "subset_truth_df = subset_truth_df[subset_c_types]\n",
    "\n",
    "# Minor\n",
    "minor_truth_df = pd.read_csv(\n",
    "    Path(minor_prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "minor_truth_df = minor_truth_df[minor_c_types]\n",
    "\n",
    "# Major\n",
    "major_truth_df = pd.read_csv(\n",
    "    Path(major_prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "major_truth_df = major_truth_df[major_c_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1027e2",
   "metadata": {},
   "source": [
    "#### Extract lineages metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lineage mapping of all cell types in the data\n",
    "lineages_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_immune_lineages.tsv\"),\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# Replace columns\n",
    "lineages_df.rename(\n",
    "    columns={\n",
    "        \"celltype_major\": \"Major Cell Type\",\n",
    "        \"celltype_major_short\": \"Annotated Major Cell Type\",\n",
    "        \"celltype_minor\": \"Minor Cell Type\",\n",
    "        \"celltype_minor_short\": \"Annotated Minor Cell Type\",\n",
    "        \"celltype_subset\": \"Subset Cell Type\",\n",
    "        \"celltype_subset_short\": \"Annotated Subset Cell Type\",\n",
    "        \"marker_genes\": \"Marker Genes\",\n",
    "        \"counts\": \"Cell Counts\",\n",
    "        \"num_of_patients\": \"Patient Counts\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We removed Myeloid_c7_Monocyte_3_FCGR3A, exclude it from the lineages DataFrame\n",
    "lineages_df = lineages_df[\n",
    "    lineages_df[\"Subset Cell Type\"] != \"Myeloid_c7_Monocyte_3_FCGR3A\"\n",
    "]\n",
    "\n",
    "# We also removed 3 cell types that MuSiC dropped\n",
    "lineages_df = lineages_df[\n",
    "    ~lineages_df[\"Subset Cell Type\"].isin(\n",
    "        [\n",
    "            \"Myeloid_c0_DC_LAMP3\",\n",
    "            \"Myeloid_c5_Macrophage_3_SIGLEC1\",\n",
    "            \"T_cells_c5_CD8+_GZMK\",\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48907a",
   "metadata": {},
   "source": [
    "#### Extract colour pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37963d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lineage mapping of all cell types in the data\n",
    "colour_pallete_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_colour_pallete.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Convert to dictionary\n",
    "colour_pallete_d = {\n",
    "    row[\"all_celltype\"]: {\"fill\": row[\"fill\"], \"line\": row[\"line\"]}\n",
    "    for i, row in colour_pallete_df.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8a4a8",
   "metadata": {},
   "source": [
    "## [Fig] Stacked bar charts of false positives/negatives at major lineage level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify methods and tumour purity levels\n",
    "methods = [\n",
    "    \"scaden\",\n",
    "    \"bprism_v2\",\n",
    "    \"dwls\",\n",
    "    \"cbx\",\n",
    "    \"music\",\n",
    "    \"bisque\",\n",
    "    \"hspe\",\n",
    "    \"epic\",\n",
    "    \"cpm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce55348",
   "metadata": {},
   "source": [
    "#### Major cell types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_preds_truth_l = []\n",
    "\n",
    "for method in tqdm(methods):\n",
    "    # Read predictions and filter predictions and groundtruth of 50% tumour\n",
    "    res_df = pd.read_csv(\n",
    "        Path(major_prefix).joinpath(f\"data/results/{method}.csv\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Some predictions can be like this -0.00000000013\n",
    "    # Round them up to 0%\n",
    "    res_df[res_df < 0] = 0\n",
    "\n",
    "    # Extract 50% tumour purity level\n",
    "    tmp_truth_df = major_truth_df[\n",
    "        major_truth_df[\"Cancer Epithelial\"] == pur_lvl\n",
    "    ].sort_index()\n",
    "    tmp_res_df = res_df[res_df.index.isin(tmp_truth_df.index)].sort_index()\n",
    "\n",
    "    # Iterate over cell types\n",
    "    for c_type in tmp_truth_df.columns.tolist():\n",
    "        ctype_truth_df = tmp_truth_df[c_type]\n",
    "        ctype_preds_df = tmp_res_df[c_type]\n",
    "\n",
    "        # Concatenate predictions and groundtruth into a DataFrame\n",
    "        preds_truth_df = pd.concat(\n",
    "            [ctype_truth_df.sort_index(), ctype_preds_df.sort_index()], axis=1\n",
    "        )\n",
    "        preds_truth_df.columns = [\"truth\", \"preds\"]\n",
    "        preds_truth_df = preds_truth_df * 100\n",
    "        preds_truth_df[\"Patient\"] = [i.split(\"_\")[0] for i in preds_truth_df.index]\n",
    "        preds_truth_df[\"Cell Type\"] = c_type\n",
    "        preds_truth_df[\"Method\"] = method\n",
    "\n",
    "        major_preds_truth_l.append(preds_truth_df)\n",
    "\n",
    "major_preds_truth_df = pd.concat(major_preds_truth_l, axis=0)\n",
    "\n",
    "# Assign lineage level\n",
    "major_preds_truth_df[\"lineage\"] = \"major\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3abc5",
   "metadata": {},
   "source": [
    "#### Minor cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc019cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_preds_truth_l = []\n",
    "\n",
    "for method in tqdm(methods):\n",
    "    # Read predictions and filter predictions and groundtruth of 50% tumour\n",
    "    res_df = pd.read_csv(\n",
    "        Path(minor_prefix).joinpath(f\"data/results/{method}.csv\"), sep=\"\\t\", index_col=0\n",
    "    )\n",
    "\n",
    "    # Some predictions can be like this -0.00000000013\n",
    "    # Round them up to 0%\n",
    "    res_df[res_df < 0] = 0\n",
    "\n",
    "    # Extract 50% tumour purity level\n",
    "    tmp_truth_df = minor_truth_df[\n",
    "        minor_truth_df[\"Cancer Epithelial\"] == pur_lvl\n",
    "    ].sort_index()\n",
    "    tmp_res_df = res_df[res_df.index.isin(tmp_truth_df.index)].sort_index()\n",
    "\n",
    "    # Iterate over cell types\n",
    "    for c_type in tmp_truth_df.columns.tolist():\n",
    "        ctype_truth_df = tmp_truth_df[c_type]\n",
    "        ctype_preds_df = tmp_res_df[c_type]\n",
    "\n",
    "        # Concatenate predictions and groundtruth into a DataFrame\n",
    "        preds_truth_df = pd.concat(\n",
    "            [ctype_truth_df.sort_index(), ctype_preds_df.sort_index()], axis=1\n",
    "        )\n",
    "        preds_truth_df.columns = [\"truth\", \"preds\"]\n",
    "        preds_truth_df = preds_truth_df * 100\n",
    "        preds_truth_df[\"Patient\"] = [i.split(\"_\")[0] for i in preds_truth_df.index]\n",
    "        preds_truth_df[\"Cell Type\"] = c_type\n",
    "        preds_truth_df[\"Method\"] = method\n",
    "\n",
    "        minor_preds_truth_l.append(preds_truth_df)\n",
    "\n",
    "minor_preds_truth_df = pd.concat(minor_preds_truth_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract minor immune cell types\n",
    "minor_immune_ctypes = lineages_df[\n",
    "    lineages_df[\"Major Cell Type\"].isin([\"T-cells\", \"B-cells\", \"Myeloid\"])\n",
    "][\"Minor Cell Type\"].unique()\n",
    "\n",
    "minor_preds_truth_df = minor_preds_truth_df[\n",
    "    minor_preds_truth_df[\"Cell Type\"].isin(minor_immune_ctypes.tolist())\n",
    "]\n",
    "\n",
    "# Fix Cycling_Myeloid\n",
    "minor_preds_truth_df.replace({\"Cycling_Myeloid\": \"Cycling Myeloid\"}, inplace=True)\n",
    "\n",
    "# Assign lineage level\n",
    "minor_preds_truth_df[\"lineage\"] = \"minor\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d552a",
   "metadata": {},
   "source": [
    "#### Subset cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_preds_truth_l = []\n",
    "\n",
    "for method in tqdm(methods):\n",
    "    # Read predictions and filter predictions and groundtruth of 50% tumour\n",
    "    res_df = pd.read_csv(\n",
    "        Path(subset_prefix).joinpath(f\"data/results/{method}.csv\"),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "    # Some predictions can be like this -0.00000000013\n",
    "    # Round them up to 0%\n",
    "    res_df[res_df < 0] = 0\n",
    "\n",
    "    # Extract 50% tumour purity level\n",
    "    tmp_truth_df = subset_truth_df[\n",
    "        subset_truth_df[\"Cancer Epithelial\"] == pur_lvl\n",
    "    ].sort_index()\n",
    "    tmp_res_df = res_df[res_df.index.isin(tmp_truth_df.index)].sort_index()\n",
    "\n",
    "    # Iterate over cell types\n",
    "    for c_type in tmp_truth_df.columns.tolist():\n",
    "        ctype_truth_df = tmp_truth_df[c_type]\n",
    "        ctype_preds_df = tmp_res_df[c_type]\n",
    "\n",
    "        # Concatenate predictions and groundtruth into a DataFrame\n",
    "        preds_truth_df = pd.concat(\n",
    "            [ctype_truth_df.sort_index(), ctype_preds_df.sort_index()], axis=1\n",
    "        )\n",
    "        preds_truth_df.columns = [\"truth\", \"preds\"]\n",
    "        preds_truth_df = preds_truth_df * 100\n",
    "        preds_truth_df[\"Patient\"] = [i.split(\"_\")[0] for i in preds_truth_df.index]\n",
    "        preds_truth_df[\"Cell Type\"] = c_type\n",
    "        preds_truth_df[\"Method\"] = method\n",
    "\n",
    "        subset_preds_truth_l.append(preds_truth_df)\n",
    "\n",
    "subset_preds_truth_df = pd.concat(subset_preds_truth_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58171558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subset immune cell types\n",
    "subset_immune_ctypes = lineages_df[\n",
    "    lineages_df[\"Minor Cell Type\"].isin(\n",
    "        [\"T cells CD4+\", \"T cells CD8+\", \"Macrophage\", \"Monocyte\", \"DCs\"]\n",
    "    )\n",
    "][\"Subset Cell Type\"].unique()\n",
    "\n",
    "subset_preds_truth_df = subset_preds_truth_df[\n",
    "    subset_preds_truth_df[\"Cell Type\"].isin(subset_immune_ctypes.tolist())\n",
    "]\n",
    "\n",
    "# Get pretty subset annotations\n",
    "subset_preds_truth_df.rename(columns={\"Cell Type\": \"Subset Cell Type\"}, inplace=True)\n",
    "subset_preds_truth_df = (\n",
    "    subset_preds_truth_df.reset_index()\n",
    "    .merge(\n",
    "        lineages_df[[\"Subset Cell Type\", \"Annotated Subset Cell Type\"]],\n",
    "        how=\"left\",\n",
    "        on=\"Subset Cell Type\",\n",
    "    )\n",
    "    .set_index(\"index\")\n",
    ")\n",
    "\n",
    "# Drop ugly names and add lineage level\n",
    "subset_preds_truth_df = subset_preds_truth_df.drop([\"Subset Cell Type\"], axis=1).rename(\n",
    "    columns={\"Annotated Subset Cell Type\": \"Cell Type\"}\n",
    ")\n",
    "\n",
    "# Assign lineage level\n",
    "subset_preds_truth_df[\"lineage\"] = \"subset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b51b8",
   "metadata": {},
   "source": [
    "#### Concatenate and bin preds/truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f72ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate across lineage levels\n",
    "all_preds_truth_df = pd.concat(\n",
    "    [major_preds_truth_df, minor_preds_truth_df, subset_preds_truth_df], axis=0\n",
    ")\n",
    "\n",
    "# Bin predictions\n",
    "bins = [-0.0000000001, 0.1, 1, 10, 100]\n",
    "labels = [\"<0.1\", \"0.1-1\", \"1-10\", \">10\"]\n",
    "all_preds_truth_df[\"preds_binned\"] = pd.cut(\n",
    "    all_preds_truth_df[\"preds\"], bins=bins, labels=labels\n",
    ")\n",
    "\n",
    "# Bin truth\n",
    "bins = [-0.0000000001, 0.1, 1, 10, 100]\n",
    "labels = [\"<0.1\", \"0.1-1\", \"1-10\", \">10\"]\n",
    "all_preds_truth_df[\"truth_binned\"] = pd.cut(\n",
    "    all_preds_truth_df[\"truth\"], bins=bins, labels=labels\n",
    ")\n",
    "\n",
    "# Replace method with proper names\n",
    "all_preds_truth_df.replace(\n",
    "    {\n",
    "        \"scaden\": \"Scaden\",\n",
    "        \"music\": \"MuSiC\",\n",
    "        \"cbx\": \"CBX\",\n",
    "        \"dwls\": \"DWLS\",\n",
    "        \"cpm\": \"CPM\",\n",
    "        \"epic\": \"EPIC\",\n",
    "        \"bprism_v2\": \"BayesPrism\",\n",
    "        \"bisque\": \"Bisque\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673ec3d",
   "metadata": {},
   "source": [
    "#### Plot stacked bar chart of all cell types and each cell type together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bad2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-axis order\n",
    "xaxis_order_d = {\n",
    "    \"major\": [\n",
    "        \"All Cell Type\",\n",
    "        \"Cancer Epithelial\",\n",
    "        \"Normal Epithelial\",\n",
    "        \"T-cells\",\n",
    "        \"B-cells\",\n",
    "        \"Myeloid\",\n",
    "        \"Endothelial\",\n",
    "        \"CAFs\",\n",
    "        \"PVL\",\n",
    "        \"Plasmablasts\",\n",
    "    ],\n",
    "    \"minor\": [\n",
    "        \"All Cell Type\",\n",
    "        \"NK cells\",\n",
    "        \"Cycling T-cells\",\n",
    "        \"NKT cells\",\n",
    "        \"T cells CD4+\",\n",
    "        \"T cells CD8+\",\n",
    "        \"B cells Memory\",\n",
    "        \"B cells Naive\",\n",
    "        \"Cycling Myeloid\",\n",
    "        \"Macrophage\",\n",
    "        \"Monocyte\",\n",
    "        \"DCs\",\n",
    "    ],\n",
    "    \"subset\": [\n",
    "        \"All Cell Type\",\n",
    "        \"Naive/central Memory T Cells\",\n",
    "        \"Effector Memory T Cells\",\n",
    "        \"T-regs\",\n",
    "        \"Tfh\",\n",
    "        \"Chemokine-expressing T Cells\",\n",
    "        \"IFN-I Signature T Cells\",\n",
    "        \"T-cells:IFNG\",\n",
    "        \"T-cells:LAG3\",\n",
    "        \"M2-like Macrophage:EGR1\",\n",
    "        \"LAM2*\",\n",
    "        \"LAM1*\",\n",
    "        \"M2-like Macrophage:CXCL10\",\n",
    "        \"Mono:IL1B\",\n",
    "        \"Mono:FCGR3A\",\n",
    "        \"Myeloid:pDC/IRF7\",\n",
    "        \"Myeloid:cDC2/CD1C\",\n",
    "        \"Myeloid:cDC1/CLEC9A\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension for png image according to each lineage level\n",
    "f_pos_d = {\n",
    "    \"major\": {\n",
    "        \"width\": 850,\n",
    "        \"height\": 2000,\n",
    "        \"x_domains_all\": 0.105,\n",
    "        \"x_domains_ctype\": 0.13,\n",
    "    },\n",
    "    \"minor\": {\n",
    "        \"width\": 800,\n",
    "        \"height\": 650,\n",
    "        \"x_domains_all\": 0.0925,\n",
    "        \"x_domains_ctype\": 0.105,\n",
    "    },\n",
    "    \"subset\": {\n",
    "        \"width\": 1200,\n",
    "        \"height\": 825,\n",
    "        \"x_domains_all\": 0.062,\n",
    "        \"x_domains_ctype\": 0.07,\n",
    "    },\n",
    "}\n",
    "\n",
    "f_neg_d = {\n",
    "    \"major\": {\n",
    "        \"width\": 850,\n",
    "        \"height\": 2000,\n",
    "        \"x_domains_all\": 0.105,\n",
    "        \"x_domains_ctype\": 0.13,\n",
    "    },\n",
    "    \"minor\": {\n",
    "        \"width\": 800,\n",
    "        \"height\": 650,\n",
    "        \"x_domains_all\": 0.0925,\n",
    "        \"x_domains_ctype\": 0.105,\n",
    "    },\n",
    "    \"subset\": {\n",
    "        \"width\": 1200,\n",
    "        \"height\": 825,\n",
    "        \"x_domains_all\": 0.062,\n",
    "        \"x_domains_ctype\": 0.07,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53588d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once with for \"minor\" and once with \"subset\"\n",
    "lineage_lvl = \"minor\"\n",
    "methods_order = [\"BayesPrism\", \"DWLS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1f3a6",
   "metadata": {},
   "source": [
    "False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d116ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive colour map\n",
    "fp_tn_color_map = {\n",
    "    \"0.1-1\": \"rgb(221, 136, 172)\",  # px.colors.sequential.Magenta[::2][1:]\n",
    "    \"1-10\": \"rgb(177, 77, 142)\",\n",
    "    \">10\": \"rgb(108, 33, 103)\",\n",
    "    \"<0.1\": \"rgb(185, 219, 244)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a46ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_false_positives(\n",
    "    df: pd.DataFrame,\n",
    "    y_axis_val: str,\n",
    "    y_axis_title: str,\n",
    "    y_axis_range: List,\n",
    "    d_tick: int,\n",
    "    color_var: str,\n",
    "    bins: List,\n",
    "    lineage_lvl: str,\n",
    "    color_map: Dict,\n",
    "    counts_df: pd.DataFrame,\n",
    "    methods_order: List,\n",
    "    row_spacing: float = 0.025,\n",
    "    col_spacing: float = 0.025,\n",
    ") -> None:\n",
    "\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        x=\"Cell Type\",\n",
    "        y=y_axis_val,\n",
    "        color=color_var,\n",
    "        facet_row=\"Method\",\n",
    "        facet_row_spacing=row_spacing,\n",
    "        facet_col=\"Col Type\",\n",
    "        facet_col_spacing=col_spacing,\n",
    "        category_orders={\n",
    "            \"Prediction bins\": bins,\n",
    "            \"Method\": methods_order,\n",
    "            \"Col Type\": [\"All Cell Type\", \"Each Cell Type\"],\n",
    "        },\n",
    "        color_discrete_map=color_map,\n",
    "    )\n",
    "\n",
    "    # Update axes\n",
    "    fig.update_xaxes(\n",
    "        ticks=\"outside\",\n",
    "        tickangle=90,\n",
    "        tickfont_size=22,\n",
    "        linecolor=\"black\",\n",
    "        side=\"bottom\",\n",
    "        categoryorder=\"array\",\n",
    "        categoryarray=np.array(xaxis_order_d[lineage_lvl]),\n",
    "        title_font_size=23,\n",
    "        matches=None,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        ticks=\"outside\",\n",
    "        linecolor=\"black\",\n",
    "        range=y_axis_range,\n",
    "        dtick=d_tick,\n",
    "        tickfont_size=22,\n",
    "        showgrid=True,\n",
    "        gridwidth=0.5,\n",
    "        gridcolor=\"lightgray\",\n",
    "    )\n",
    "\n",
    "    # Resize domain of x axes so training subplot takes up 70% of the plot\n",
    "    fig.update_xaxes(\n",
    "        domain=[0.0, f_pos_d[lineage_lvl][\"x_domains_all\"]], col=1, title=\"\"\n",
    "    )\n",
    "    fig.update_xaxes(domain=[f_pos_d[lineage_lvl][\"x_domains_ctype\"], 1], col=2)\n",
    "    fig.update_yaxes(title=\"\", title_font_size=1, title_standoff=0, col=1)\n",
    "\n",
    "    # Update layout\n",
    "    fig[\"layout\"].update(\n",
    "        barmode=\"relative\",\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        showlegend=False,\n",
    "        margin=dict(t=50, l=0, r=22, b=0),\n",
    "        font_color=\"black\",\n",
    "    )\n",
    "\n",
    "    # Format method names. If not method names, remove it\n",
    "    fig.for_each_annotation(\n",
    "        lambda a: a.update(text=f\"{a.text.split('=')[-1]}\", x=0.997, font_size=20)\n",
    "        if a.text.split(\"=\")[-1] in methods_order\n",
    "        else a.update(text=\"\")\n",
    "    )\n",
    "\n",
    "    # Add annotation for each method\n",
    "    for method, c_type in itertools.product(methods_order, xaxis_order_d[lineage_lvl]):\n",
    "        pct = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Percentage\",\n",
    "        ].values[0]\n",
    "        count = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Count\",\n",
    "        ].values[0]\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=c_type,\n",
    "            y=pct,\n",
    "            text=f\"<i>{int(count)}</i>\",\n",
    "            showarrow=False,\n",
    "            yshift=7,\n",
    "            font_size=18,\n",
    "            row=len(methods_order) - methods_order.index(method),\n",
    "            col=(lambda x: 1 if x == \"All Cell Type\" else 0)(\n",
    "                c_type\n",
    "            ),  # Column 1 if \"All Cell Type\",\n",
    "        )\n",
    "\n",
    "    # Add total annotation\n",
    "    for c_type in xaxis_order_d[lineage_lvl]:\n",
    "        count = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == \"All methods\") & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Count\",\n",
    "        ].values[0]\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=c_type,\n",
    "            y=101,\n",
    "            text=f\"<i>n=<br>{int(count)}</i>\",\n",
    "            showarrow=False,\n",
    "            yshift=34,\n",
    "            font_size=18,\n",
    "            row=len(methods_order),\n",
    "            col=(lambda x: 1 if x == \"All Cell Type\" else 0)(\n",
    "                c_type\n",
    "            ),  # Column 1 if \"All Cell Type\",\n",
    "        )\n",
    "\n",
    "    # Save image\n",
    "    fig.write_image(\n",
    "        Path(\n",
    "            f\"figures/supp_figures/supp_fig_15a_fp_{lineage_lvl}_{y_axis_val.lower()}\"\n",
    "        ).with_suffix(\".svg\"),\n",
    "        width=f_pos_d[lineage_lvl][\"width\"],\n",
    "        height=f_pos_d[lineage_lvl][\"height\"],\n",
    "        scale=5,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract partitions where truth = 0%\n",
    "false_positive_df = all_preds_truth_df[\n",
    "    (all_preds_truth_df[\"lineage\"] == lineage_lvl) & (all_preds_truth_df[\"truth\"] < 0.1)\n",
    "]\n",
    "\n",
    "# Counts number of unique prediction bins per method per cell type\n",
    "counts_false_positive_df = (\n",
    "    false_positive_df[[\"Cell Type\", \"Method\", \"preds_binned\"]]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Mixtures Count\", \"preds_binned\": \"Prediction bins\"})\n",
    "    # .replace(methods_annotation)\n",
    ")\n",
    "counts_false_positive_df.columns.name = None\n",
    "\n",
    "# Pivot to get [method, cell type] as columns and [bins] as rows\n",
    "pivot_counts_false_positive_df = pd.pivot_table(\n",
    "    counts_false_positive_df,\n",
    "    values=\"Mixtures Count\",\n",
    "    columns=[\"Method\", \"Cell Type\"],\n",
    "    index=[\"Prediction bins\"],\n",
    ").fillna(0)\n",
    "\n",
    "### Calculate false positive for each cell type ####\n",
    "# Normalize to 100% (i.e. sum total of each colum and divide each cell by its column total)\n",
    "normalized_false_positive_df = pivot_counts_false_positive_df.div(\n",
    "    pivot_counts_false_positive_df.sum(axis=0), axis=1\n",
    ")\n",
    "\n",
    "# \"Melt\" DataFrame from long to wide\n",
    "normalized_false_positive_df = (\n",
    "    normalized_false_positive_df.reset_index()\n",
    "    .melt(id_vars=[\"Prediction bins\"])\n",
    "    .rename(columns={\"value\": \"Percentage\"})\n",
    ")\n",
    "\n",
    "# Merge normalized with counts to have normalized and counts in one DataFrame\n",
    "# Also rename \"Mixtures Count\" to \"Count\"\n",
    "per_ctype_false_positive_df = counts_false_positive_df.merge(\n",
    "    normalized_false_positive_df,\n",
    "    on=[\"Cell Type\", \"Method\", \"Prediction bins\"],\n",
    "    how=\"left\",\n",
    ").rename(columns={\"Mixtures Count\": \"Count\"})\n",
    "\n",
    "# Assign column type (for plotting)\n",
    "per_ctype_false_positive_df[\"Col Type\"] = \"Each Cell Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate false positive across all cell type ####\n",
    "# Calculate total counts and percentages across all cell types\n",
    "all_ctype_counts_false_positive_df = pivot_counts_false_positive_df.sum(axis=1, level=0)\n",
    "all_ctype_normalized_false_positive_df = all_ctype_counts_false_positive_df.div(\n",
    "    all_ctype_counts_false_positive_df.sum(axis=0), axis=1\n",
    ")\n",
    "all_ctype_false_positive_df = pd.merge(\n",
    "    left=all_ctype_counts_false_positive_df.reset_index()\n",
    "    .melt(id_vars=[\"Prediction bins\"])\n",
    "    .rename(columns={\"value\": \"Count\"}),\n",
    "    right=all_ctype_normalized_false_positive_df.reset_index()\n",
    "    .melt(id_vars=[\"Prediction bins\"])\n",
    "    .rename(columns={\"value\": \"Percentage\"}),\n",
    "    on=[\"Prediction bins\", \"Method\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "all_ctype_false_positive_df[\"Cell Type\"] = \"All Cell Type\"\n",
    "\n",
    "# Assign column type (for plotting)\n",
    "all_ctype_false_positive_df[\"Col Type\"] = \"All Cell Type\"\n",
    "\n",
    "# Concatenate per-cell-type and all-cell-type false positives\n",
    "total_false_positive_df = pd.concat(\n",
    "    [per_ctype_false_positive_df, all_ctype_false_positive_df], axis=0\n",
    ")\n",
    "total_false_positive_df[\"Percentage\"] = total_false_positive_df[\"Percentage\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare method-specific cell counts\n",
    "counts_df = (\n",
    "    total_false_positive_df[total_false_positive_df[\"Prediction bins\"] != \"<0.1\"][\n",
    "        [\"Method\", \"Cell Type\", \"Count\", \"Percentage\"]\n",
    "    ]\n",
    "    .groupby(by=[\"Method\", \"Cell Type\"], dropna=False)\n",
    "    .agg(\"sum\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Prepare cell counts\n",
    "total_counts_df = (\n",
    "    total_false_positive_df[total_false_positive_df[\"Method\"] == \"BayesPrism\"]\n",
    "    .groupby([\"Cell Type\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "total_counts_df[\"Method\"] = \"All methods\"\n",
    "\n",
    "# Concatenate all methods counts back into counts_df\n",
    "counts_df = pd.concat([counts_df, total_counts_df], axis=0)\n",
    "\n",
    "# If something doesn't exist, replace it by 0\n",
    "for method in methods_order + [\"All methods\"]:\n",
    "    for c_type in xaxis_order_d[lineage_lvl]:\n",
    "        if counts_df[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type)\n",
    "        ].empty:\n",
    "            counts_df.loc[len(counts_df.index)] = [method, c_type, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save source data\n",
    "total_false_positive_df[\n",
    "    (total_false_positive_df[\"Prediction bins\"] != \"<0.1\")\n",
    "    & (total_false_positive_df[\"Method\"].isin(methods_order))\n",
    "].to_csv(Path(viz_prefix).joinpath(\"source_data/supp_figure_15a.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentages while ignore True Positives\n",
    "plot_false_positives(\n",
    "    df=total_false_positive_df[\n",
    "        (total_false_positive_df[\"Prediction bins\"] != \"<0.1\")\n",
    "        & (total_false_positive_df[\"Method\"].isin(methods_order))\n",
    "    ],\n",
    "    y_axis_val=\"Percentage\",\n",
    "    y_axis_title=\"FPR (%)\",  # \"Percentage (%)\",\n",
    "    y_axis_range=[0, 101],\n",
    "    d_tick=20,\n",
    "    color_var=\"Prediction bins\",\n",
    "    bins=[\"0.1-1\", \"1-10\", \">10\", \"<0.1\"],\n",
    "    lineage_lvl=lineage_lvl,\n",
    "    color_map=fp_tn_color_map,\n",
    "    counts_df=counts_df[counts_df[\"Method\"].isin([\"All methods\"] + methods_order)],\n",
    "    methods_order=methods_order,\n",
    "    # row_spacing=0.05,  # remove if plot major cell type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73b6eb",
   "metadata": {},
   "source": [
    "False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c857842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negative color maps\n",
    "fn_tp_color_map = {\n",
    "    \"0.1-1\": \"rgb(108, 192, 139)\",  # px.colors.sequential.Emrld[::2][1:]\n",
    "    \"1-10\": \"rgb(33, 122, 121)\",\n",
    "    \">10\": \"rgb(7, 64, 80)\",\n",
    "    \"tp\": \"rgb(222, 219, 238)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_false_negatives(\n",
    "    df: pd.DataFrame,\n",
    "    y_axis_val: str,\n",
    "    y_axis_title: str,\n",
    "    y_axis_range: List,\n",
    "    color_var: str,\n",
    "    bins: List,\n",
    "    lineage_lvl: str,\n",
    "    color_map: Dict,\n",
    "    counts_df: pd.DataFrame,\n",
    "    methods_order: List,\n",
    "    row_spacing: float = 0.025,\n",
    "    col_spacing: float = 0.025,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        -\n",
    "\n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        x=\"Cell Type\",\n",
    "        y=y_axis_val,\n",
    "        color=color_var,\n",
    "        facet_row=\"Method\",\n",
    "        facet_row_spacing=row_spacing,\n",
    "        facet_col=\"Col Type\",\n",
    "        facet_col_spacing=col_spacing,\n",
    "        category_orders={\n",
    "            \"Groundtruth bins\": bins,\n",
    "            \"Method\": methods_order,\n",
    "            \"Col Type\": [\"All Cell Type\", \"Each Cell Type\"],\n",
    "        },\n",
    "        color_discrete_map=color_map,\n",
    "    )\n",
    "\n",
    "    # Update axes\n",
    "    fig.update_xaxes(\n",
    "        ticks=\"outside\",\n",
    "        tickangle=90,\n",
    "        tickfont_size=22,\n",
    "        linecolor=\"black\",\n",
    "        side=\"bottom\",\n",
    "        categoryorder=\"array\",\n",
    "        categoryarray=np.array(xaxis_order_d[lineage_lvl]),\n",
    "        title_font_size=23,\n",
    "        matches=None,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        ticks=\"outside\",\n",
    "        linecolor=\"black\",\n",
    "        range=y_axis_range,\n",
    "        dtick=20,\n",
    "        tickfont_size=22,\n",
    "        showgrid=True,\n",
    "        gridwidth=0.5,\n",
    "        gridcolor=\"lightgray\",\n",
    "    )\n",
    "\n",
    "    # Resize domain of x axes so training subplot takes up 70% of the plot\n",
    "    fig.update_xaxes(\n",
    "        domain=[0.0, f_pos_d[lineage_lvl][\"x_domains_all\"]],\n",
    "        col=1,\n",
    "        title=\"\",\n",
    "    )\n",
    "    fig.update_xaxes(domain=[f_pos_d[lineage_lvl][\"x_domains_ctype\"], 1], col=2)\n",
    "    fig.update_yaxes(title=\"\", title_font_size=1, title_standoff=0, col=1)\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        categoryorder=\"array\",\n",
    "        categoryarray=np.array(xaxis_order_d[lineage_lvl]),\n",
    "        col=2,\n",
    "        row=1,\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig[\"layout\"].update(\n",
    "        barmode=\"relative\",\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        showlegend=False,\n",
    "        margin=dict(t=50, l=0, r=22, b=0),\n",
    "        font_color=\"black\",\n",
    "    )\n",
    "\n",
    "    # Format method names. If not method names, remove it\n",
    "    fig.for_each_annotation(\n",
    "        lambda a: a.update(text=f\"{a.text.split('=')[-1]}\", x=0.997, font_size=20)\n",
    "        if a.text.split(\"=\")[-1] in methods_order\n",
    "        else a.update(text=\"\")\n",
    "    )\n",
    "\n",
    "    # Add annotation for each method\n",
    "    for method, c_type in itertools.product(methods_order, xaxis_order_d[lineage_lvl]):\n",
    "        pct = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Percentage\",\n",
    "        ].values[0]\n",
    "        count = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Count\",\n",
    "        ].values[0]\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=c_type,\n",
    "            y=pct,\n",
    "            text=f\"<i>{int(count)}</i>\",\n",
    "            showarrow=False,\n",
    "            yshift=7,\n",
    "            font_size=15,\n",
    "            row=len(methods_order) - methods_order.index(method),\n",
    "            col=(lambda x: 1 if x == \"All Cell Type\" else 0)(\n",
    "                c_type\n",
    "            ),  # Column 1 if \"All Cell Type\",\n",
    "        )\n",
    "\n",
    "    # Add total annotation\n",
    "    for c_type in xaxis_order_d[lineage_lvl]:\n",
    "        count = counts_df.loc[\n",
    "            (counts_df[\"Method\"] == \"All methods\") & (counts_df[\"Cell Type\"] == c_type),\n",
    "            \"Count\",\n",
    "        ].values[0]\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=c_type,\n",
    "            y=101,\n",
    "            text=f\"<i>n=<br>{int(count)}</i>\",\n",
    "            showarrow=False,\n",
    "            yshift=34,\n",
    "            font_size=18,\n",
    "            row=len(methods_order),\n",
    "            col=(lambda x: 1 if x == \"All Cell Type\" else 0)(\n",
    "                c_type\n",
    "            ),  # Column 1 if \"All Cell Type\",\n",
    "        )\n",
    "\n",
    "    # Save image\n",
    "    fig.write_image(\n",
    "        Path(\n",
    "            f\"figures/supp_figures/supp_fig_15b_fn_{lineage_lvl}_{y_axis_val.lower()}\"\n",
    "        ).with_suffix(\".svg\"),\n",
    "        width=f_neg_d[lineage_lvl][\"width\"],\n",
    "        height=f_neg_d[lineage_lvl][\"height\"],\n",
    "        scale=5,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract partitions where truth = 0%\n",
    "false_negative_df = all_preds_truth_df[\n",
    "    (all_preds_truth_df[\"lineage\"] == lineage_lvl)\n",
    "    & (all_preds_truth_df[\"preds\"] < 0.1)\n",
    "    & (all_preds_truth_df[\"truth_binned\"] != \"<0.1\")\n",
    "]\n",
    "\n",
    "# Counts number of unique prediction bins per method per cell type\n",
    "counts_false_negative_df = (\n",
    "    false_negative_df[[\"Cell Type\", \"Method\", \"truth_binned\"]]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Mixtures Count\", \"truth_binned\": \"Groundtruth bins\"})\n",
    "    # .replace(methods_annotation)\n",
    ")\n",
    "counts_false_negative_df.columns.name = None\n",
    "\n",
    "# Calculate true positives\n",
    "tp_df = all_preds_truth_df[\n",
    "    (all_preds_truth_df[\"lineage\"] == lineage_lvl)\n",
    "    & (all_preds_truth_df[\"preds\"] >= 0.1)\n",
    "    & (all_preds_truth_df[\"truth_binned\"] != \"<0.1\")\n",
    "]\n",
    "\n",
    "tp_df = (\n",
    "    tp_df[[\"Cell Type\", \"Method\"]]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Mixtures Count\"})\n",
    "    # .replace(methods_annotation)\n",
    ")\n",
    "tp_df.columns.name = None\n",
    "\n",
    "tp_df[\"Groundtruth bins\"] = \"tp\"\n",
    "\n",
    "# Concatenate true positives back into temp_preds_truth_df\n",
    "counts_false_negative_df = pd.concat([counts_false_negative_df, tp_df], axis=0)\n",
    "\n",
    "# Pivot to get [method, cell type] as columns and [bins] as rows\n",
    "pivot_counts_false_negative_df = pd.pivot_table(\n",
    "    counts_false_negative_df,\n",
    "    values=\"Mixtures Count\",\n",
    "    columns=[\"Method\", \"Cell Type\"],\n",
    "    index=[\"Groundtruth bins\"],\n",
    ").fillna(0)\n",
    "\n",
    "### Calculate false negative for each cell type ####\n",
    "# Normalize to 100% (i.e. sum total of each colum and divide each cell by its column total)\n",
    "normalized_false_negative_df = pivot_counts_false_negative_df.div(\n",
    "    pivot_counts_false_negative_df.sum(axis=0), axis=1\n",
    ")\n",
    "\n",
    "# \"Melt\" DataFrame from long to wide\n",
    "normalized_false_negative_df = (\n",
    "    normalized_false_negative_df.reset_index()\n",
    "    .melt(id_vars=[\"Groundtruth bins\"])\n",
    "    .rename(columns={\"value\": \"Percentage\"})\n",
    ")\n",
    "\n",
    "# Merge normalized with counts to have normalized and counts in one DataFrame\n",
    "# Also rename \"Mixtures Count\" to \"Count\"\n",
    "per_ctype_false_negative_df = counts_false_negative_df.merge(\n",
    "    normalized_false_negative_df,\n",
    "    on=[\"Cell Type\", \"Method\", \"Groundtruth bins\"],\n",
    "    how=\"left\",\n",
    ").rename(columns={\"Mixtures Count\": \"Count\"})\n",
    "\n",
    "# Assign column type (for plotting)\n",
    "per_ctype_false_negative_df[\"Col Type\"] = \"Each Cell Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate false negative across all cell type ####\n",
    "# Calculate total counts and percentages across all cell types\n",
    "all_ctype_counts_false_negative_df = pivot_counts_false_negative_df.sum(axis=1, level=0)\n",
    "all_ctype_normalized_false_negative_df = all_ctype_counts_false_negative_df.div(\n",
    "    all_ctype_counts_false_negative_df.sum(axis=0), axis=1\n",
    ")\n",
    "all_ctype_false_negative_df = pd.merge(\n",
    "    left=all_ctype_counts_false_negative_df.reset_index()\n",
    "    .melt(id_vars=[\"Groundtruth bins\"])\n",
    "    .rename(columns={\"value\": \"Count\"}),\n",
    "    right=all_ctype_normalized_false_negative_df.reset_index()\n",
    "    .melt(id_vars=[\"Groundtruth bins\"])\n",
    "    .rename(columns={\"value\": \"Percentage\"}),\n",
    "    on=[\"Groundtruth bins\", \"Method\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "all_ctype_false_negative_df[\"Cell Type\"] = \"All Cell Type\"\n",
    "\n",
    "# Assign column type (for plotting)\n",
    "all_ctype_false_negative_df[\"Col Type\"] = \"All Cell Type\"\n",
    "\n",
    "# Concatenate per-cell-type and all-cell-type false negatives\n",
    "total_false_negative_df = pd.concat(\n",
    "    [per_ctype_false_negative_df, all_ctype_false_negative_df], axis=0\n",
    ")\n",
    "total_false_negative_df[\"Percentage\"] = total_false_negative_df[\"Percentage\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give Scaden and CPM one entry so they appear\n",
    "if lineage_lvl == \"major\":\n",
    "    total_false_negative_df.loc[len(total_false_negative_df.index)] = [\n",
    "        \"Cancer Epithelial\",\n",
    "        \"Scaden\",\n",
    "        \"0.1-1\",\n",
    "        0,\n",
    "        0,\n",
    "        \"Each Cell Type\",\n",
    "    ]\n",
    "elif lineage_lvl == \"minor\":\n",
    "    total_false_negative_df.loc[len(total_false_negative_df.index)] = [\n",
    "        \"DCs\",\n",
    "        \"Scaden\",\n",
    "        \"0.1-1\",\n",
    "        0,\n",
    "        0,\n",
    "        \"Each Cell Type\",\n",
    "    ]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "total_false_negative_df.loc[len(total_false_negative_df.index)] = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"CPM\",\n",
    "    \"0.1-1\",\n",
    "    0,\n",
    "    0,\n",
    "    \"Each Cell Type\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359199b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare method-specific cell counts\n",
    "counts_df = (\n",
    "    total_false_negative_df[total_false_negative_df[\"Groundtruth bins\"] != \"tp\"][\n",
    "        [\"Method\", \"Cell Type\", \"Count\", \"Percentage\"]\n",
    "    ]\n",
    "    .groupby(by=[\"Method\", \"Cell Type\"], dropna=False)\n",
    "    .agg(\"sum\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Prepare cell counts\n",
    "total_counts_df = (\n",
    "    total_false_negative_df[total_false_negative_df[\"Method\"] == \"BayesPrism\"]\n",
    "    .groupby([\"Cell Type\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "total_counts_df[\"Method\"] = \"All methods\"\n",
    "\n",
    "# Concatenate all methods counts back into counts_df\n",
    "counts_df = pd.concat([counts_df, total_counts_df], axis=0)\n",
    "\n",
    "# If something doesn't exist, replace it by 0\n",
    "for method in methods_order + [\"All methods\"]:\n",
    "    for c_type in xaxis_order_d[lineage_lvl]:\n",
    "        if counts_df[\n",
    "            (counts_df[\"Method\"] == method) & (counts_df[\"Cell Type\"] == c_type)\n",
    "        ].empty:\n",
    "            counts_df.loc[len(counts_df.index)] = [method, c_type, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e339f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save source data\n",
    "total_false_negative_df[\n",
    "    (total_false_negative_df[\"Groundtruth bins\"] != \"tp\")\n",
    "    & (total_false_negative_df[\"Method\"].isin(methods_order))\n",
    "].to_csv(Path(viz_prefix).joinpath(\"source_data/supp_figure_15b.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentages\n",
    "fig = plot_false_negatives(\n",
    "    df=total_false_negative_df[\n",
    "        (total_false_negative_df[\"Groundtruth bins\"] != \"tp\")\n",
    "        & (total_false_negative_df[\"Method\"].isin(methods_order))\n",
    "    ],\n",
    "    y_axis_val=\"Percentage\",\n",
    "    y_axis_title=\"FNR (%)\",\n",
    "    y_axis_range=[0, 101],\n",
    "    color_var=\"Groundtruth bins\",\n",
    "    bins=[\"0.1-1\", \"1-10\", \">10\", \"tp\"],\n",
    "    lineage_lvl=lineage_lvl,\n",
    "    color_map=fn_tp_color_map,\n",
    "    counts_df=counts_df,\n",
    "    methods_order=methods_order,\n",
    "    # row_spacing=0.05,  # remove if plot major cell type\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e21e3183055704cdc6beb302a7eaad42e1c0671a451dc4bde87185c59632390"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
