{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7cc55-3b46-46c2-bdd6-6e34ffdc37f1",
   "metadata": {},
   "source": [
    "# Visualize models performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a63a1-8e52-493c-b685-5a419fa97191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as adata\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly as plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity as skl_cosine\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine as scipy_cosine\n",
    "from scipy.spatial.distance import braycurtis, cdist\n",
    "from math import sqrt\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cef7f-433e-4db0-8f5f-942d374522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix to visualizations folder\n",
    "viz_prefix = \"???/deconvolution_benchmarking/visualizations\"\n",
    "\n",
    "# Prefix to the experiment we're plotting\n",
    "prefix = \"???/deconvolution_benchmarking/01_purity_levels_experiment/include_normal_epithelial\"\n",
    "\n",
    "# Tumour purity levels\n",
    "purity_levels = np.arange(0.05, 1, 0.05).round(3).tolist()\n",
    "\n",
    "# Cell types\n",
    "c_types = [\n",
    "    \"Cancer Epithelial\",\n",
    "    \"Normal Epithelial\",\n",
    "    \"T-cells\",\n",
    "    \"B-cells\",\n",
    "    \"Myeloid\",\n",
    "    \"CAFs\",\n",
    "    \"Endothelial\",\n",
    "    \"PVL\",\n",
    "    \"Plasmablasts\",\n",
    "]\n",
    "\n",
    "# Methods order is universal across figures\n",
    "methods_order = [\n",
    "    \"BayesPrism\",\n",
    "    \"Scaden\",\n",
    "    \"MuSiC\",\n",
    "    \"hspe\",\n",
    "    \"DWLS\",\n",
    "    \"CBX\",\n",
    "    \"Bisque\",\n",
    "    \"EPIC\",\n",
    "    \"CPM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77080247",
   "metadata": {},
   "source": [
    "### Load groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562086a-5077-43a2-989e-422ee88109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load truth.csv\n",
    "truth_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/results/truth.csv\"), sep=\"\\t\", index_col=0\n",
    ")\n",
    "truth_df = truth_df[c_types]\n",
    "\n",
    "# Pivot longer for when we need it\n",
    "truth_copy_df = truth_df.copy().sample(frac=0.05, random_state=41)\n",
    "truth_copy_df[\"purity_level\"] = truth_copy_df[\"Cancer Epithelial\"]\n",
    "\n",
    "pivot_truth_df = (\n",
    "    truth_copy_df.reset_index()\n",
    "    .melt(id_vars=[\"index\", \"purity_level\"], value_vars=c_types)\n",
    "    .rename(columns={\"index\": \"mixture_id\", \"variable\": \"cell_type\", \"value\": \"truth\"})\n",
    "    .set_index([\"mixture_id\", \"cell_type\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565677a",
   "metadata": {},
   "source": [
    "### Extract colour pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract colour pallete\n",
    "ctype_colour_pallete_df = pd.read_csv(\n",
    "    Path(prefix).joinpath(\"data/Whole_miniatlas_colour_pallete.csv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Convert to dictionary\n",
    "ctype_colour_pallete_d = {\n",
    "    row[\"all_celltype\"]: {\"fill\": row[\"fill\"], \"line\": row[\"line\"]}\n",
    "    for i, row in ctype_colour_pallete_df.iterrows()\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "090ae385",
   "metadata": {},
   "source": [
    "## [Fig 4a]. Confusion matrix of each method for each cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c238b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"bprism_v2\",\n",
    "    \"scaden\",\n",
    "    \"music\",\n",
    "    \"cpm\",\n",
    "    \"cbx\",\n",
    "    \"hspe\",\n",
    "    \"epic\",\n",
    "    \"bisque\",\n",
    "    \"dwls\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0511a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_truth_l = []\n",
    "\n",
    "for method in tqdm(methods):\n",
    "    res_df = pd.read_csv(\n",
    "        Path(prefix).joinpath(f\"data/results/{method}.csv\"), sep=\"\\t\", index_col=0\n",
    "    )\n",
    "    res_df = res_df[c_types]\n",
    "\n",
    "    # Clip tiny negative numbers to 0\n",
    "    res_df.clip(lower=0, inplace=True)\n",
    "\n",
    "    # We only use samples at 50% tumour purity level\n",
    "    tmp_truth_df = truth_df[truth_df[\"Cancer Epithelial\"] == 0.5].sort_index()\n",
    "    tmp_res_df = res_df[res_df.index.isin(tmp_truth_df.index)].sort_index()\n",
    "\n",
    "    # Set index name to \"mixture_id\". We'll need it later\n",
    "    tmp_truth_df.index.name = \"mixture_id\"\n",
    "    tmp_res_df.index.name = \"mixture_id\"\n",
    "\n",
    "    # Check if indexes match\n",
    "    assert (tmp_res_df.sort_index().index == tmp_truth_df.sort_index().index).all()\n",
    "    assert (tmp_res_df.sort_index().columns == tmp_truth_df.sort_index().columns).all()\n",
    "\n",
    "    # Merge prediction and groundtruth\n",
    "    tmp_pred_truth_df = (\n",
    "        tmp_res_df.reset_index()\n",
    "        .melt(id_vars=[\"mixture_id\"], var_name=\"cell_type\", value_name=\"pred\")\n",
    "        .merge(\n",
    "            tmp_truth_df.reset_index().melt(\n",
    "                id_vars=[\"mixture_id\"], var_name=\"cell_type\", value_name=\"truth\"\n",
    "            ),\n",
    "            left_on=[\"mixture_id\", \"cell_type\"],\n",
    "            right_on=[\"mixture_id\", \"cell_type\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Assign method\n",
    "    tmp_pred_truth_df[\"method\"] = method\n",
    "\n",
    "    # Append to rmse_l\n",
    "    pred_truth_l.append(tmp_pred_truth_df)\n",
    "\n",
    "# Concatenate all rmse dataframes\n",
    "pred_truth_df = pd.concat(pred_truth_l, axis=0)\n",
    "\n",
    "# Rename method names\n",
    "pred_truth_df.replace(\n",
    "    {\n",
    "        \"scaden\": \"Scaden\",\n",
    "        \"music\": \"MuSiC\",\n",
    "        \"cbx\": \"CBX\",\n",
    "        \"bisque\": \"Bisque\",\n",
    "        \"dwls\": \"DWLS\",\n",
    "        \"epic\": \"EPIC\",\n",
    "        \"cpm\": \"CPM\",\n",
    "        \"bprism_v2\": \"BayesPrism\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Bin predictions\n",
    "bins = [-0.0000000001, 0.1, 100]\n",
    "labels = [\"<0.1\", \">=0.1\"]\n",
    "pred_truth_df[\"pred_binned\"] = pd.cut(\n",
    "    pred_truth_df[\"pred\"] * 100, bins=bins, labels=labels\n",
    ")\n",
    "\n",
    "# Bin truth\n",
    "bins = [-0.0000000001, 0.1, 100]\n",
    "labels = [\"<0.1\", \">=0.1\"]\n",
    "pred_truth_df[\"truth_binned\"] = pd.cut(\n",
    "    pred_truth_df[\"truth\"] * 100, bins=bins, labels=labels\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca496a5",
   "metadata": {},
   "source": [
    "#### Plot only all cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplots with 9 columns (methods) and 1 row\n",
    "fig = make_subplots(rows=1, cols=9, vertical_spacing=0.025)\n",
    "\n",
    "# Iterate over each method and create confusion matrix\n",
    "for i, method in enumerate(methods_order):\n",
    "    # Create confusion for all cell types\n",
    "    method_pred_truth_df = pred_truth_df[(pred_truth_df[\"method\"] == method)]\n",
    "\n",
    "    confusion = confusion_matrix(\n",
    "        method_pred_truth_df[\"truth_binned\"], method_pred_truth_df[\"pred_binned\"]\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        px.imshow(\n",
    "            confusion.transpose() / 1000,\n",
    "            text_auto=True,\n",
    "            color_continuous_scale=\"Purples\",\n",
    "            x=[\"<0.1\", \">=0.1\"],\n",
    "            y=[\"<0.1\", \">=0.1\"],\n",
    "        ).data[0],\n",
    "        1,\n",
    "        i + 1,\n",
    "    )\n",
    "\n",
    "# # Specify the text template for the annotations\n",
    "# fig.update_traces(texttemplate=\"%{text}\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    # title=\"Actual proportions\",\n",
    "    titlefont_size=10,\n",
    "    title_standoff=1,\n",
    "    ticks=\"outside\",\n",
    "    showticklabels=True,\n",
    "    tickmode=\"array\",\n",
    "    tickwidth=0.75,\n",
    "    ticklen=2,\n",
    "    tickfont_size=12,\n",
    "    linecolor=\"black\",\n",
    "    linewidth=0.75,\n",
    "    side=\"bottom\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    # title=\"Predicted proportions\",\n",
    "    titlefont_size=10,\n",
    "    title_standoff=1,\n",
    "    linecolor=\"black\",\n",
    "    linewidth=0.75,\n",
    "    ticks=\"outside\",\n",
    "    showticklabels=False,\n",
    "    tickwidth=0.75,\n",
    "    ticklen=2,\n",
    "    tickfont_size=12,\n",
    ")\n",
    "\n",
    "# Add ticks to first column and first row\n",
    "fig.update_yaxes(\n",
    "    col=1,\n",
    "    ticks=\"outside\",\n",
    "    showticklabels=True,\n",
    "    tickwidth=0.75,\n",
    "    ticklen=2,\n",
    "    tickfont_size=12,\n",
    ")\n",
    "\n",
    "fig[\"layout\"].update(\n",
    "    coloraxis=dict(\n",
    "        colorscale=\"Purples\",\n",
    "        showscale=False,\n",
    "        cmax=10,\n",
    "        cmin=0,\n",
    "        colorbar=dict(\n",
    "            ticks=\"outside\",\n",
    "            ticksuffix=\"\",\n",
    "            tickfont_size=16,\n",
    "            dtick=1,\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.5,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "        ),\n",
    "    ),\n",
    "    margin=dict(t=0, l=0, r=0, b=0),\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(size=10, color=\"black\"),\n",
    ")\n",
    "fig.write_image(\n",
    "    \"figures/main_figures/main_fig_4a.svg\",\n",
    "    width=750,\n",
    "    height=100,\n",
    "    # # Uncomment this to display colorbar\n",
    "    # height=300,\n",
    "    scale=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrices into source data\n",
    "all_confusion_l = []\n",
    "\n",
    "# Iterate over each method and create confusion matrix\n",
    "for i, method in enumerate(methods_order):\n",
    "    # Create confusion for all cell types\n",
    "    method_pred_truth_df = pred_truth_df[(pred_truth_df[\"method\"] == method)]\n",
    "\n",
    "    confusion = confusion_matrix(\n",
    "        method_pred_truth_df[\"truth_binned\"], method_pred_truth_df[\"pred_binned\"]\n",
    "    )\n",
    "\n",
    "    # Flatten and append to all_confusion_l\n",
    "    all_confusion_l.append(\n",
    "        pd.DataFrame(\n",
    "            [confusion.flatten()],\n",
    "            index=[method],\n",
    "            columns=[\n",
    "                \"True negatives\",\n",
    "                \"False positives\",\n",
    "                \"False negatives\",\n",
    "                \"True positives\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "all_confusion_df = pd.concat(all_confusion_l, axis=0)\n",
    "all_confusion_df.to_csv(\n",
    "    Path(viz_prefix).joinpath(\"source_data/figure_4a.tsv\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799dabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e21e3183055704cdc6beb302a7eaad42e1c0671a451dc4bde87185c59632390"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
